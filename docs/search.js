window.pdocSearch = (function(){
/** elasticlunr - http://weixsong.github.io * Copyright (C) 2017 Oliver Nightingale * Copyright (C) 2017 Wei Song * MIT Licensed */!function(){function e(e){if(null===e||"object"!=typeof e)return e;var t=e.constructor();for(var n in e)e.hasOwnProperty(n)&&(t[n]=e[n]);return t}var t=function(e){var n=new t.Index;return n.pipeline.add(t.trimmer,t.stopWordFilter,t.stemmer),e&&e.call(n,n),n};t.version="0.9.5",lunr=t,t.utils={},t.utils.warn=function(e){return function(t){e.console&&console.warn&&console.warn(t)}}(this),t.utils.toString=function(e){return void 0===e||null===e?"":e.toString()},t.EventEmitter=function(){this.events={}},t.EventEmitter.prototype.addListener=function(){var e=Array.prototype.slice.call(arguments),t=e.pop(),n=e;if("function"!=typeof t)throw new TypeError("last argument must be a function");n.forEach(function(e){this.hasHandler(e)||(this.events[e]=[]),this.events[e].push(t)},this)},t.EventEmitter.prototype.removeListener=function(e,t){if(this.hasHandler(e)){var n=this.events[e].indexOf(t);-1!==n&&(this.events[e].splice(n,1),0==this.events[e].length&&delete this.events[e])}},t.EventEmitter.prototype.emit=function(e){if(this.hasHandler(e)){var t=Array.prototype.slice.call(arguments,1);this.events[e].forEach(function(e){e.apply(void 0,t)},this)}},t.EventEmitter.prototype.hasHandler=function(e){return e in this.events},t.tokenizer=function(e){if(!arguments.length||null===e||void 0===e)return[];if(Array.isArray(e)){var n=e.filter(function(e){return null===e||void 0===e?!1:!0});n=n.map(function(e){return t.utils.toString(e).toLowerCase()});var i=[];return n.forEach(function(e){var n=e.split(t.tokenizer.seperator);i=i.concat(n)},this),i}return e.toString().trim().toLowerCase().split(t.tokenizer.seperator)},t.tokenizer.defaultSeperator=/[\s\-]+/,t.tokenizer.seperator=t.tokenizer.defaultSeperator,t.tokenizer.setSeperator=function(e){null!==e&&void 0!==e&&"object"==typeof e&&(t.tokenizer.seperator=e)},t.tokenizer.resetSeperator=function(){t.tokenizer.seperator=t.tokenizer.defaultSeperator},t.tokenizer.getSeperator=function(){return t.tokenizer.seperator},t.Pipeline=function(){this._queue=[]},t.Pipeline.registeredFunctions={},t.Pipeline.registerFunction=function(e,n){n in t.Pipeline.registeredFunctions&&t.utils.warn("Overwriting existing registered function: "+n),e.label=n,t.Pipeline.registeredFunctions[n]=e},t.Pipeline.getRegisteredFunction=function(e){return e in t.Pipeline.registeredFunctions!=!0?null:t.Pipeline.registeredFunctions[e]},t.Pipeline.warnIfFunctionNotRegistered=function(e){var n=e.label&&e.label in this.registeredFunctions;n||t.utils.warn("Function is not registered with pipeline. This may cause problems when serialising the index.\n",e)},t.Pipeline.load=function(e){var n=new t.Pipeline;return e.forEach(function(e){var i=t.Pipeline.getRegisteredFunction(e);if(!i)throw new Error("Cannot load un-registered function: "+e);n.add(i)}),n},t.Pipeline.prototype.add=function(){var e=Array.prototype.slice.call(arguments);e.forEach(function(e){t.Pipeline.warnIfFunctionNotRegistered(e),this._queue.push(e)},this)},t.Pipeline.prototype.after=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i+1,0,n)},t.Pipeline.prototype.before=function(e,n){t.Pipeline.warnIfFunctionNotRegistered(n);var i=this._queue.indexOf(e);if(-1===i)throw new Error("Cannot find existingFn");this._queue.splice(i,0,n)},t.Pipeline.prototype.remove=function(e){var t=this._queue.indexOf(e);-1!==t&&this._queue.splice(t,1)},t.Pipeline.prototype.run=function(e){for(var t=[],n=e.length,i=this._queue.length,o=0;n>o;o++){for(var r=e[o],s=0;i>s&&(r=this._queue[s](r,o,e),void 0!==r&&null!==r);s++);void 0!==r&&null!==r&&t.push(r)}return t},t.Pipeline.prototype.reset=function(){this._queue=[]},t.Pipeline.prototype.get=function(){return this._queue},t.Pipeline.prototype.toJSON=function(){return this._queue.map(function(e){return t.Pipeline.warnIfFunctionNotRegistered(e),e.label})},t.Index=function(){this._fields=[],this._ref="id",this.pipeline=new t.Pipeline,this.documentStore=new t.DocumentStore,this.index={},this.eventEmitter=new t.EventEmitter,this._idfCache={},this.on("add","remove","update",function(){this._idfCache={}}.bind(this))},t.Index.prototype.on=function(){var e=Array.prototype.slice.call(arguments);return this.eventEmitter.addListener.apply(this.eventEmitter,e)},t.Index.prototype.off=function(e,t){return this.eventEmitter.removeListener(e,t)},t.Index.load=function(e){e.version!==t.version&&t.utils.warn("version mismatch: current "+t.version+" importing "+e.version);var n=new this;n._fields=e.fields,n._ref=e.ref,n.documentStore=t.DocumentStore.load(e.documentStore),n.pipeline=t.Pipeline.load(e.pipeline),n.index={};for(var i in e.index)n.index[i]=t.InvertedIndex.load(e.index[i]);return n},t.Index.prototype.addField=function(e){return this._fields.push(e),this.index[e]=new t.InvertedIndex,this},t.Index.prototype.setRef=function(e){return this._ref=e,this},t.Index.prototype.saveDocument=function(e){return this.documentStore=new t.DocumentStore(e),this},t.Index.prototype.addDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.addDoc(i,e),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));this.documentStore.addFieldLength(i,n,o.length);var r={};o.forEach(function(e){e in r?r[e]+=1:r[e]=1},this);for(var s in r){var u=r[s];u=Math.sqrt(u),this.index[n].addToken(s,{ref:i,tf:u})}},this),n&&this.eventEmitter.emit("add",e,this)}},t.Index.prototype.removeDocByRef=function(e){if(e&&this.documentStore.isDocStored()!==!1&&this.documentStore.hasDoc(e)){var t=this.documentStore.getDoc(e);this.removeDoc(t,!1)}},t.Index.prototype.removeDoc=function(e,n){if(e){var n=void 0===n?!0:n,i=e[this._ref];this.documentStore.hasDoc(i)&&(this.documentStore.removeDoc(i),this._fields.forEach(function(n){var o=this.pipeline.run(t.tokenizer(e[n]));o.forEach(function(e){this.index[n].removeToken(e,i)},this)},this),n&&this.eventEmitter.emit("remove",e,this))}},t.Index.prototype.updateDoc=function(e,t){var t=void 0===t?!0:t;this.removeDocByRef(e[this._ref],!1),this.addDoc(e,!1),t&&this.eventEmitter.emit("update",e,this)},t.Index.prototype.idf=function(e,t){var n="@"+t+"/"+e;if(Object.prototype.hasOwnProperty.call(this._idfCache,n))return this._idfCache[n];var i=this.index[t].getDocFreq(e),o=1+Math.log(this.documentStore.length/(i+1));return this._idfCache[n]=o,o},t.Index.prototype.getFields=function(){return this._fields.slice()},t.Index.prototype.search=function(e,n){if(!e)return[];e="string"==typeof e?{any:e}:JSON.parse(JSON.stringify(e));var i=null;null!=n&&(i=JSON.stringify(n));for(var o=new t.Configuration(i,this.getFields()).get(),r={},s=Object.keys(e),u=0;u<s.length;u++){var a=s[u];r[a]=this.pipeline.run(t.tokenizer(e[a]))}var l={};for(var c in o){var d=r[c]||r.any;if(d){var f=this.fieldSearch(d,c,o),h=o[c].boost;for(var p in f)f[p]=f[p]*h;for(var p in f)p in l?l[p]+=f[p]:l[p]=f[p]}}var v,g=[];for(var p in l)v={ref:p,score:l[p]},this.documentStore.hasDoc(p)&&(v.doc=this.documentStore.getDoc(p)),g.push(v);return g.sort(function(e,t){return t.score-e.score}),g},t.Index.prototype.fieldSearch=function(e,t,n){var i=n[t].bool,o=n[t].expand,r=n[t].boost,s=null,u={};return 0!==r?(e.forEach(function(e){var n=[e];1==o&&(n=this.index[t].expandToken(e));var r={};n.forEach(function(n){var o=this.index[t].getDocs(n),a=this.idf(n,t);if(s&&"AND"==i){var l={};for(var c in s)c in o&&(l[c]=o[c]);o=l}n==e&&this.fieldSearchStats(u,n,o);for(var c in o){var d=this.index[t].getTermFrequency(n,c),f=this.documentStore.getFieldLength(c,t),h=1;0!=f&&(h=1/Math.sqrt(f));var p=1;n!=e&&(p=.15*(1-(n.length-e.length)/n.length));var v=d*a*h*p;c in r?r[c]+=v:r[c]=v}},this),s=this.mergeScores(s,r,i)},this),s=this.coordNorm(s,u,e.length)):void 0},t.Index.prototype.mergeScores=function(e,t,n){if(!e)return t;if("AND"==n){var i={};for(var o in t)o in e&&(i[o]=e[o]+t[o]);return i}for(var o in t)o in e?e[o]+=t[o]:e[o]=t[o];return e},t.Index.prototype.fieldSearchStats=function(e,t,n){for(var i in n)i in e?e[i].push(t):e[i]=[t]},t.Index.prototype.coordNorm=function(e,t,n){for(var i in e)if(i in t){var o=t[i].length;e[i]=e[i]*o/n}return e},t.Index.prototype.toJSON=function(){var e={};return this._fields.forEach(function(t){e[t]=this.index[t].toJSON()},this),{version:t.version,fields:this._fields,ref:this._ref,documentStore:this.documentStore.toJSON(),index:e,pipeline:this.pipeline.toJSON()}},t.Index.prototype.use=function(e){var t=Array.prototype.slice.call(arguments,1);t.unshift(this),e.apply(this,t)},t.DocumentStore=function(e){this._save=null===e||void 0===e?!0:e,this.docs={},this.docInfo={},this.length=0},t.DocumentStore.load=function(e){var t=new this;return t.length=e.length,t.docs=e.docs,t.docInfo=e.docInfo,t._save=e.save,t},t.DocumentStore.prototype.isDocStored=function(){return this._save},t.DocumentStore.prototype.addDoc=function(t,n){this.hasDoc(t)||this.length++,this.docs[t]=this._save===!0?e(n):null},t.DocumentStore.prototype.getDoc=function(e){return this.hasDoc(e)===!1?null:this.docs[e]},t.DocumentStore.prototype.hasDoc=function(e){return e in this.docs},t.DocumentStore.prototype.removeDoc=function(e){this.hasDoc(e)&&(delete this.docs[e],delete this.docInfo[e],this.length--)},t.DocumentStore.prototype.addFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&(this.docInfo[e]||(this.docInfo[e]={}),this.docInfo[e][t]=n)},t.DocumentStore.prototype.updateFieldLength=function(e,t,n){null!==e&&void 0!==e&&0!=this.hasDoc(e)&&this.addFieldLength(e,t,n)},t.DocumentStore.prototype.getFieldLength=function(e,t){return null===e||void 0===e?0:e in this.docs&&t in this.docInfo[e]?this.docInfo[e][t]:0},t.DocumentStore.prototype.toJSON=function(){return{docs:this.docs,docInfo:this.docInfo,length:this.length,save:this._save}},t.stemmer=function(){var e={ational:"ate",tional:"tion",enci:"ence",anci:"ance",izer:"ize",bli:"ble",alli:"al",entli:"ent",eli:"e",ousli:"ous",ization:"ize",ation:"ate",ator:"ate",alism:"al",iveness:"ive",fulness:"ful",ousness:"ous",aliti:"al",iviti:"ive",biliti:"ble",logi:"log"},t={icate:"ic",ative:"",alize:"al",iciti:"ic",ical:"ic",ful:"",ness:""},n="[^aeiou]",i="[aeiouy]",o=n+"[^aeiouy]*",r=i+"[aeiou]*",s="^("+o+")?"+r+o,u="^("+o+")?"+r+o+"("+r+")?$",a="^("+o+")?"+r+o+r+o,l="^("+o+")?"+i,c=new RegExp(s),d=new RegExp(a),f=new RegExp(u),h=new RegExp(l),p=/^(.+?)(ss|i)es$/,v=/^(.+?)([^s])s$/,g=/^(.+?)eed$/,m=/^(.+?)(ed|ing)$/,y=/.$/,S=/(at|bl|iz)$/,x=new RegExp("([^aeiouylsz])\\1$"),w=new RegExp("^"+o+i+"[^aeiouwxy]$"),I=/^(.+?[^aeiou])y$/,b=/^(.+?)(ational|tional|enci|anci|izer|bli|alli|entli|eli|ousli|ization|ation|ator|alism|iveness|fulness|ousness|aliti|iviti|biliti|logi)$/,E=/^(.+?)(icate|ative|alize|iciti|ical|ful|ness)$/,D=/^(.+?)(al|ance|ence|er|ic|able|ible|ant|ement|ment|ent|ou|ism|ate|iti|ous|ive|ize)$/,F=/^(.+?)(s|t)(ion)$/,_=/^(.+?)e$/,P=/ll$/,k=new RegExp("^"+o+i+"[^aeiouwxy]$"),z=function(n){var i,o,r,s,u,a,l;if(n.length<3)return n;if(r=n.substr(0,1),"y"==r&&(n=r.toUpperCase()+n.substr(1)),s=p,u=v,s.test(n)?n=n.replace(s,"$1$2"):u.test(n)&&(n=n.replace(u,"$1$2")),s=g,u=m,s.test(n)){var z=s.exec(n);s=c,s.test(z[1])&&(s=y,n=n.replace(s,""))}else if(u.test(n)){var z=u.exec(n);i=z[1],u=h,u.test(i)&&(n=i,u=S,a=x,l=w,u.test(n)?n+="e":a.test(n)?(s=y,n=n.replace(s,"")):l.test(n)&&(n+="e"))}if(s=I,s.test(n)){var z=s.exec(n);i=z[1],n=i+"i"}if(s=b,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+e[o])}if(s=E,s.test(n)){var z=s.exec(n);i=z[1],o=z[2],s=c,s.test(i)&&(n=i+t[o])}if(s=D,u=F,s.test(n)){var z=s.exec(n);i=z[1],s=d,s.test(i)&&(n=i)}else if(u.test(n)){var z=u.exec(n);i=z[1]+z[2],u=d,u.test(i)&&(n=i)}if(s=_,s.test(n)){var z=s.exec(n);i=z[1],s=d,u=f,a=k,(s.test(i)||u.test(i)&&!a.test(i))&&(n=i)}return s=P,u=d,s.test(n)&&u.test(n)&&(s=y,n=n.replace(s,"")),"y"==r&&(n=r.toLowerCase()+n.substr(1)),n};return z}(),t.Pipeline.registerFunction(t.stemmer,"stemmer"),t.stopWordFilter=function(e){return e&&t.stopWordFilter.stopWords[e]!==!0?e:void 0},t.clearStopWords=function(){t.stopWordFilter.stopWords={}},t.addStopWords=function(e){null!=e&&Array.isArray(e)!==!1&&e.forEach(function(e){t.stopWordFilter.stopWords[e]=!0},this)},t.resetStopWords=function(){t.stopWordFilter.stopWords=t.defaultStopWords},t.defaultStopWords={"":!0,a:!0,able:!0,about:!0,across:!0,after:!0,all:!0,almost:!0,also:!0,am:!0,among:!0,an:!0,and:!0,any:!0,are:!0,as:!0,at:!0,be:!0,because:!0,been:!0,but:!0,by:!0,can:!0,cannot:!0,could:!0,dear:!0,did:!0,"do":!0,does:!0,either:!0,"else":!0,ever:!0,every:!0,"for":!0,from:!0,get:!0,got:!0,had:!0,has:!0,have:!0,he:!0,her:!0,hers:!0,him:!0,his:!0,how:!0,however:!0,i:!0,"if":!0,"in":!0,into:!0,is:!0,it:!0,its:!0,just:!0,least:!0,let:!0,like:!0,likely:!0,may:!0,me:!0,might:!0,most:!0,must:!0,my:!0,neither:!0,no:!0,nor:!0,not:!0,of:!0,off:!0,often:!0,on:!0,only:!0,or:!0,other:!0,our:!0,own:!0,rather:!0,said:!0,say:!0,says:!0,she:!0,should:!0,since:!0,so:!0,some:!0,than:!0,that:!0,the:!0,their:!0,them:!0,then:!0,there:!0,these:!0,they:!0,"this":!0,tis:!0,to:!0,too:!0,twas:!0,us:!0,wants:!0,was:!0,we:!0,were:!0,what:!0,when:!0,where:!0,which:!0,"while":!0,who:!0,whom:!0,why:!0,will:!0,"with":!0,would:!0,yet:!0,you:!0,your:!0},t.stopWordFilter.stopWords=t.defaultStopWords,t.Pipeline.registerFunction(t.stopWordFilter,"stopWordFilter"),t.trimmer=function(e){if(null===e||void 0===e)throw new Error("token should not be undefined");return e.replace(/^\W+/,"").replace(/\W+$/,"")},t.Pipeline.registerFunction(t.trimmer,"trimmer"),t.InvertedIndex=function(){this.root={docs:{},df:0}},t.InvertedIndex.load=function(e){var t=new this;return t.root=e.root,t},t.InvertedIndex.prototype.addToken=function(e,t,n){for(var n=n||this.root,i=0;i<=e.length-1;){var o=e[i];o in n||(n[o]={docs:{},df:0}),i+=1,n=n[o]}var r=t.ref;n.docs[r]?n.docs[r]={tf:t.tf}:(n.docs[r]={tf:t.tf},n.df+=1)},t.InvertedIndex.prototype.hasToken=function(e){if(!e)return!1;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return!1;t=t[e[n]]}return!0},t.InvertedIndex.prototype.getNode=function(e){if(!e)return null;for(var t=this.root,n=0;n<e.length;n++){if(!t[e[n]])return null;t=t[e[n]]}return t},t.InvertedIndex.prototype.getDocs=function(e){var t=this.getNode(e);return null==t?{}:t.docs},t.InvertedIndex.prototype.getTermFrequency=function(e,t){var n=this.getNode(e);return null==n?0:t in n.docs?n.docs[t].tf:0},t.InvertedIndex.prototype.getDocFreq=function(e){var t=this.getNode(e);return null==t?0:t.df},t.InvertedIndex.prototype.removeToken=function(e,t){if(e){var n=this.getNode(e);null!=n&&t in n.docs&&(delete n.docs[t],n.df-=1)}},t.InvertedIndex.prototype.expandToken=function(e,t,n){if(null==e||""==e)return[];var t=t||[];if(void 0==n&&(n=this.getNode(e),null==n))return t;n.df>0&&t.push(e);for(var i in n)"docs"!==i&&"df"!==i&&this.expandToken(e+i,t,n[i]);return t},t.InvertedIndex.prototype.toJSON=function(){return{root:this.root}},t.Configuration=function(e,n){var e=e||"";if(void 0==n||null==n)throw new Error("fields should not be null");this.config={};var i;try{i=JSON.parse(e),this.buildUserConfig(i,n)}catch(o){t.utils.warn("user configuration parse failed, will use default configuration"),this.buildDefaultConfig(n)}},t.Configuration.prototype.buildDefaultConfig=function(e){this.reset(),e.forEach(function(e){this.config[e]={boost:1,bool:"OR",expand:!1}},this)},t.Configuration.prototype.buildUserConfig=function(e,n){var i="OR",o=!1;if(this.reset(),"bool"in e&&(i=e.bool||i),"expand"in e&&(o=e.expand||o),"fields"in e)for(var r in e.fields)if(n.indexOf(r)>-1){var s=e.fields[r],u=o;void 0!=s.expand&&(u=s.expand),this.config[r]={boost:s.boost||0===s.boost?s.boost:1,bool:s.bool||i,expand:u}}else t.utils.warn("field name in user configuration not found in index instance fields");else this.addAllFields2UserConfig(i,o,n)},t.Configuration.prototype.addAllFields2UserConfig=function(e,t,n){n.forEach(function(n){this.config[n]={boost:1,bool:e,expand:t}},this)},t.Configuration.prototype.get=function(){return this.config},t.Configuration.prototype.reset=function(){this.config={}},lunr.SortedSet=function(){this.length=0,this.elements=[]},lunr.SortedSet.load=function(e){var t=new this;return t.elements=e,t.length=e.length,t},lunr.SortedSet.prototype.add=function(){var e,t;for(e=0;e<arguments.length;e++)t=arguments[e],~this.indexOf(t)||this.elements.splice(this.locationFor(t),0,t);this.length=this.elements.length},lunr.SortedSet.prototype.toArray=function(){return this.elements.slice()},lunr.SortedSet.prototype.map=function(e,t){return this.elements.map(e,t)},lunr.SortedSet.prototype.forEach=function(e,t){return this.elements.forEach(e,t)},lunr.SortedSet.prototype.indexOf=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;){if(r===e)return o;e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o]}return r===e?o:-1},lunr.SortedSet.prototype.locationFor=function(e){for(var t=0,n=this.elements.length,i=n-t,o=t+Math.floor(i/2),r=this.elements[o];i>1;)e>r&&(t=o),r>e&&(n=o),i=n-t,o=t+Math.floor(i/2),r=this.elements[o];return r>e?o:e>r?o+1:void 0},lunr.SortedSet.prototype.intersect=function(e){for(var t=new lunr.SortedSet,n=0,i=0,o=this.length,r=e.length,s=this.elements,u=e.elements;;){if(n>o-1||i>r-1)break;s[n]!==u[i]?s[n]<u[i]?n++:s[n]>u[i]&&i++:(t.add(s[n]),n++,i++)}return t},lunr.SortedSet.prototype.clone=function(){var e=new lunr.SortedSet;return e.elements=this.toArray(),e.length=e.elements.length,e},lunr.SortedSet.prototype.union=function(e){var t,n,i;this.length>=e.length?(t=this,n=e):(t=e,n=this),i=t.clone();for(var o=0,r=n.toArray();o<r.length;o++)i.add(r[o]);return i},lunr.SortedSet.prototype.toJSON=function(){return this.toArray()},function(e,t){"function"==typeof define&&define.amd?define(t):"object"==typeof exports?module.exports=t():e.elasticlunr=t()}(this,function(){return t})}();
    /** pdoc search index */const docs = [{"fullname": "src", "modulename": "src", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.data_pipeline", "modulename": "src.data_pipeline", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.data_pipeline.etl", "modulename": "src.data_pipeline.etl", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.data_pipeline.etl.etl_pipeline", "modulename": "src.data_pipeline.etl.etl_pipeline", "kind": "module", "doc": "<p>Module that performs the ETL pipeline (Extract, Transform, Load).</p>\n"}, {"fullname": "src.data_pipeline.etl.etl_pipeline.logger", "modulename": "src.data_pipeline.etl.etl_pipeline", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger src.data_pipeline.etl.etl_pipeline (INFO)&gt;"}, {"fullname": "src.data_pipeline.etl.etl_pipeline.run", "modulename": "src.data_pipeline.etl.etl_pipeline", "qualname": "run", "kind": "function", "doc": "<p>Full ETL pipeline including extraction, transformation, and loading.</p>\n\n<p>Args:\n    input_path (str): Path to the input JSONL.gz file.\n    output_path (str): Path to save the output Parquet file.\n    tokenizer (str | None): BERT tokenizer. Defaults to None.\n    data_fraction (float): Fraction of the data to sample. Defaults to 1.\n    seed (int): Random seed for reproducibility. Defaults to 42.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">input_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">output_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">tokenizer</span><span class=\"o\">=</span><span class=\"kc\">None</span>,</span><span class=\"param\">\t<span class=\"n\">data_fraction</span><span class=\"o\">=</span><span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"mi\">42</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_pipeline.etl.extract", "modulename": "src.data_pipeline.etl.extract", "kind": "module", "doc": "<p>Module that takes care of the extraction of the raw data in an ETL pipeline.</p>\n"}, {"fullname": "src.data_pipeline.etl.extract.logger", "modulename": "src.data_pipeline.etl.extract", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger src.data_pipeline.etl.extract (INFO)&gt;"}, {"fullname": "src.data_pipeline.etl.extract.from_jsonl_gz_file", "modulename": "src.data_pipeline.etl.extract", "qualname": "from_jsonl_gz_file", "kind": "function", "doc": "<p>Returns a Spark DataFrame from the JSON objects in the gzip file.</p>\n\n<p>Args:\n    path (str): The path to the gzip file.\n    data_fraction (float): Fraction of the data to sample. Defaults to 1.\n    seed (int): Random seed for reproducibility. Defaults to 42.</p>\n\n<p>Returns:\n    DataFrame: A Spark DataFrame containing the JSON objects.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span>, </span><span class=\"param\"><span class=\"n\">data_fraction</span><span class=\"o\">=</span><span class=\"mf\">1.0</span>, </span><span class=\"param\"><span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"mi\">42</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.data_pipeline.etl.extract.from_jsonl_gz_file_pandas", "modulename": "src.data_pipeline.etl.extract", "qualname": "from_jsonl_gz_file_pandas", "kind": "function", "doc": "<p>Returns a Pandas DataFrame from the JSON objects in the gzip file.</p>\n\n<p>Args:\n    path (str): The path to the gzip file.\n    data_fraction (float): Fraction of the data to sample. Defaults to 1.0.\n    seed (int): Random seed for reproducibility. Defaults to 42.</p>\n\n<p>Returns:\n    pd.DataFrame: A Pandas DataFrame containing the JSON objects.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">data_fraction</span><span class=\"p\">:</span> <span class=\"nb\">float</span> <span class=\"o\">=</span> <span class=\"mf\">1.0</span>,</span><span class=\"param\">\t<span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"mi\">42</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.data_pipeline.etl.load", "modulename": "src.data_pipeline.etl.load", "kind": "module", "doc": "<p>Module that loads the proprocessed data back to a safe storage. Last step in ETL pipeline.</p>\n"}, {"fullname": "src.data_pipeline.etl.load.logger", "modulename": "src.data_pipeline.etl.load", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger src.data_pipeline.etl.load (INFO)&gt;"}, {"fullname": "src.data_pipeline.etl.load.to_parquet_file", "modulename": "src.data_pipeline.etl.load", "qualname": "to_parquet_file", "kind": "function", "doc": "<p>Loads the transformed data to the target location in Parquet format.</p>\n\n<p>Args:\n    df (DataFrame): Transformed data.\n    output_path (str): Path where the Parquet file will be saved.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">df</span><span class=\"p\">:</span> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>, </span><span class=\"param\"><span class=\"n\">output_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_pipeline.etl.preprocessing_pipeline", "modulename": "src.data_pipeline.etl.preprocessing_pipeline", "kind": "module", "doc": "<p>Module for preprocessing the product data for BERT-based NLP tasks.</p>\n"}, {"fullname": "src.data_pipeline.etl.preprocessing_pipeline.logger", "modulename": "src.data_pipeline.etl.preprocessing_pipeline", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger src.data_pipeline.etl.preprocessing_pipeline (INFO)&gt;"}, {"fullname": "src.data_pipeline.etl.preprocessing_pipeline.PreprocessingPipeline", "modulename": "src.data_pipeline.etl.preprocessing_pipeline", "qualname": "PreprocessingPipeline", "kind": "class", "doc": "<p>A reusable class to preprocess product data for BERT-based NLP tasks.</p>\n\n<p>Methods:\n    preprocess(df: DataFrame) -> DataFrame:\n        The entire pipeline including cleaning and text processing.</p>\n"}, {"fullname": "src.data_pipeline.etl.preprocessing_pipeline.PreprocessingPipeline.__init__", "modulename": "src.data_pipeline.etl.preprocessing_pipeline", "qualname": "PreprocessingPipeline.__init__", "kind": "function", "doc": "<p>Initializes the preprocessing pipeline with a BERT tokenizer.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">()</span>"}, {"fullname": "src.data_pipeline.etl.preprocessing_pipeline.PreprocessingPipeline.ordered_columns_to_keep", "modulename": "src.data_pipeline.etl.preprocessing_pipeline", "qualname": "PreprocessingPipeline.ordered_columns_to_keep", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_pipeline.etl.preprocessing_pipeline.PreprocessingPipeline.combined_text_column", "modulename": "src.data_pipeline.etl.preprocessing_pipeline", "qualname": "PreprocessingPipeline.combined_text_column", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.data_pipeline.etl.preprocessing_pipeline.PreprocessingPipeline.preprocess", "modulename": "src.data_pipeline.etl.preprocessing_pipeline", "qualname": "PreprocessingPipeline.preprocess", "kind": "function", "doc": "<p>Preprocess the entire pipeline including cleaning and text processing.</p>\n\n<p>Args:\n    df (DataFrame): Input dataframe with product data.</p>\n\n<p>Returns:\n    DataFrame: Preprocessed dataframe ready for training or inference.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">df</span><span class=\"p\">:</span> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.data_pipeline.etl.preprocessing_pipeline.run", "modulename": "src.data_pipeline.etl.preprocessing_pipeline", "qualname": "run", "kind": "function", "doc": "<p>Runs the preprocessing pipeline and loads it to MLflow as an artifact to be used in the inference pipeline.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.data_pipeline.etl.transform", "modulename": "src.data_pipeline.etl.transform", "kind": "module", "doc": "<p>Module that takes care of preprocessing the raw data in an ETL pipeline.</p>\n"}, {"fullname": "src.data_pipeline.etl.transform.logger", "modulename": "src.data_pipeline.etl.transform", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger src.data_pipeline.etl.transform (INFO)&gt;"}, {"fullname": "src.data_pipeline.etl.transform.bert_tokenize_text", "modulename": "src.data_pipeline.etl.transform", "qualname": "bert_tokenize_text", "kind": "function", "doc": "<p>Tokenizes text using the BERT tokenizer.</p>\n\n<p>Args:\n    df (DataFrame): Input DataFrame.\n    tokenizer (AutoTokenizer): BERT tokenizer.\n    combined_text_column (str, optional): Name of the column with the combined text. Defaults to \"combined_text\".</p>\n\n<p>Returns:\n    DataFrame: DataFrame with tokenized text column.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">df</span><span class=\"p\">:</span> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>,</span><span class=\"param\">\t<span class=\"n\">tokenizer</span><span class=\"p\">:</span> <span class=\"n\">transformers</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">auto</span><span class=\"o\">.</span><span class=\"n\">tokenization_auto</span><span class=\"o\">.</span><span class=\"n\">AutoTokenizer</span>,</span><span class=\"param\">\t<span class=\"n\">combined_text_column</span><span class=\"o\">=</span><span class=\"s1\">&#39;combined_text&#39;</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.data_pipeline.etl.transform.preprocess", "modulename": "src.data_pipeline.etl.transform", "qualname": "preprocess", "kind": "function", "doc": "<p>Preprocesses the raw data for BERT-based NLP tasks.</p>\n\n<p>Args:\n    df (DataFrame): Input DataFrame with raw data.\n    tokenizer (AutoTokenizer | None): BERT tokenizer. Defaults to None.</p>\n\n<p>Returns:\n    DataFrame: DataFrame with preprocessed data.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">df</span><span class=\"p\">:</span> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>,</span><span class=\"param\">\t<span class=\"n\">tokenizer</span><span class=\"p\">:</span> <span class=\"n\">transformers</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">auto</span><span class=\"o\">.</span><span class=\"n\">tokenization_auto</span><span class=\"o\">.</span><span class=\"n\">AutoTokenizer</span> <span class=\"o\">|</span> <span class=\"kc\">None</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.data_pipeline.utils", "modulename": "src.data_pipeline.utils", "kind": "module", "doc": "<p>Module for utility functions.</p>\n"}, {"fullname": "src.data_pipeline.utils.get_logger", "modulename": "src.data_pipeline.utils", "qualname": "get_logger", "kind": "function", "doc": "<p>Template for getting a logger.</p>\n\n<p>Args:\n    name: Name of the logger.</p>\n\n<p>Returns: Logger.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">Logger</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.inference", "modulename": "src.inference", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.inference.api", "modulename": "src.inference.api", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.inference.api.app", "modulename": "src.inference.api.app", "kind": "module", "doc": "<p>This module contains the FastAPI application and its routes.</p>\n"}, {"fullname": "src.inference.api.app.logger", "modulename": "src.inference.api.app", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger src.inference.api.app (INFO)&gt;"}, {"fullname": "src.inference.api.app.ml_artifacts", "modulename": "src.inference.api.app", "qualname": "ml_artifacts", "kind": "variable", "doc": "<p></p>\n", "default_value": "{}"}, {"fullname": "src.inference.api.app.lifespan", "modulename": "src.inference.api.app", "qualname": "lifespan", "kind": "function", "doc": "<p>Lifecycle events for the FastAPI application.</p>\n\n<p>Args:\n    app (FastAPI): The FastAPI application.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">app</span><span class=\"p\">:</span> <span class=\"n\">fastapi</span><span class=\"o\">.</span><span class=\"n\">applications</span><span class=\"o\">.</span><span class=\"n\">FastAPI</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "async def"}, {"fullname": "src.inference.api.app.app", "modulename": "src.inference.api.app", "qualname": "app", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;fastapi.applications.FastAPI object&gt;"}, {"fullname": "src.inference.api.app.check_health", "modulename": "src.inference.api.app", "qualname": "check_health", "kind": "function", "doc": "<p>Health check endpoint.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.inference.api.app.predict", "modulename": "src.inference.api.app", "qualname": "predict", "kind": "function", "doc": "<p>Predict the main category of a product based on its description.</p>\n\n<p>Args:\n    product_data (ProductDescription): The input product data.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">product_data</span><span class=\"p\">:</span> <span class=\"n\">src</span><span class=\"o\">.</span><span class=\"n\">inference</span><span class=\"o\">.</span><span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">schemas</span><span class=\"o\">.</span><span class=\"n\">product_descriptions</span><span class=\"o\">.</span><span class=\"n\">ProductDescription</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "async def"}, {"fullname": "src.inference.api.constants", "modulename": "src.inference.api.constants", "kind": "module", "doc": "<p>Module with constants used in the training pipeline.</p>\n\n<p>Attributes:\n    CATEGORIES (list[str]): List of possible product categories.</p>\n"}, {"fullname": "src.inference.api.constants.CATEGORIES", "modulename": "src.inference.api.constants", "qualname": "CATEGORIES", "kind": "variable", "doc": "<p></p>\n", "default_value": "[&#x27;All Electronics&#x27;, &#x27;Amazon Fashion&#x27;, &#x27;Amazon Home&#x27;, &#x27;Arts, Crafts &amp; Sewing&#x27;, &#x27;Automotive&#x27;, &#x27;Books&#x27;, &#x27;Camera &amp; Photo&#x27;, &#x27;Cell Phones &amp; Accessories&#x27;, &#x27;Computers&#x27;, &#x27;Digital Music&#x27;, &#x27;Grocery&#x27;, &#x27;Health &amp; Personal Care&#x27;, &#x27;Home Audio &amp; Theater&#x27;, &#x27;Industrial &amp; Scientific&#x27;, &#x27;Movies &amp; TV&#x27;, &#x27;Musical Instruments&#x27;, &#x27;Office Products&#x27;, &#x27;Pet Supplies&#x27;, &#x27;Sports &amp; Outdoors&#x27;, &#x27;Tools &amp; Home Improvement&#x27;, &#x27;Toys &amp; Games&#x27;, &#x27;Video Games&#x27;]"}, {"fullname": "src.inference.api.schemas", "modulename": "src.inference.api.schemas", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.inference.api.schemas.predictions", "modulename": "src.inference.api.schemas.predictions", "kind": "module", "doc": "<p>Module for Pydantic schema used in the API for predictions response.</p>\n"}, {"fullname": "src.inference.api.schemas.predictions.CategoryEnum", "modulename": "src.inference.api.schemas.predictions", "qualname": "CategoryEnum", "kind": "class", "doc": "<p>An enumeration.</p>\n", "bases": "enum.Enum"}, {"fullname": "src.inference.api.schemas.predictions.CategoryEnum.All_Electronics", "modulename": "src.inference.api.schemas.predictions", "qualname": "CategoryEnum.All_Electronics", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;CategoryEnum.All_Electronics: &#x27;All Electronics&#x27;&gt;"}, {"fullname": "src.inference.api.schemas.predictions.CategoryEnum.Amazon_Fashion", "modulename": "src.inference.api.schemas.predictions", "qualname": "CategoryEnum.Amazon_Fashion", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;CategoryEnum.Amazon_Fashion: &#x27;Amazon Fashion&#x27;&gt;"}, {"fullname": "src.inference.api.schemas.predictions.CategoryEnum.Amazon_Home", "modulename": "src.inference.api.schemas.predictions", "qualname": "CategoryEnum.Amazon_Home", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;CategoryEnum.Amazon_Home: &#x27;Amazon Home&#x27;&gt;"}, {"fullname": "src.inference.api.schemas.predictions.CategoryEnum.Arts_Crafts_and_Sewing", "modulename": "src.inference.api.schemas.predictions", "qualname": "CategoryEnum.Arts_Crafts_and_Sewing", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;CategoryEnum.Arts_Crafts_and_Sewing: &#x27;Arts, Crafts &amp; Sewing&#x27;&gt;"}, {"fullname": "src.inference.api.schemas.predictions.CategoryEnum.Automotive", "modulename": "src.inference.api.schemas.predictions", "qualname": "CategoryEnum.Automotive", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;CategoryEnum.Automotive: &#x27;Automotive&#x27;&gt;"}, {"fullname": "src.inference.api.schemas.predictions.CategoryEnum.Books", "modulename": "src.inference.api.schemas.predictions", "qualname": "CategoryEnum.Books", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;CategoryEnum.Books: &#x27;Books&#x27;&gt;"}, {"fullname": "src.inference.api.schemas.predictions.CategoryEnum.Camera_and_Photo", "modulename": "src.inference.api.schemas.predictions", "qualname": "CategoryEnum.Camera_and_Photo", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;CategoryEnum.Camera_and_Photo: &#x27;Camera &amp; Photo&#x27;&gt;"}, {"fullname": "src.inference.api.schemas.predictions.CategoryEnum.Cell_Phones_and_Accessories", "modulename": "src.inference.api.schemas.predictions", "qualname": "CategoryEnum.Cell_Phones_and_Accessories", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;CategoryEnum.Cell_Phones_and_Accessories: &#x27;Cell Phones &amp; Accessories&#x27;&gt;"}, {"fullname": "src.inference.api.schemas.predictions.CategoryEnum.Computers", "modulename": "src.inference.api.schemas.predictions", "qualname": "CategoryEnum.Computers", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;CategoryEnum.Computers: &#x27;Computers&#x27;&gt;"}, {"fullname": "src.inference.api.schemas.predictions.CategoryEnum.Digital_Music", "modulename": "src.inference.api.schemas.predictions", "qualname": "CategoryEnum.Digital_Music", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;CategoryEnum.Digital_Music: &#x27;Digital Music&#x27;&gt;"}, {"fullname": "src.inference.api.schemas.predictions.CategoryEnum.Grocery", "modulename": "src.inference.api.schemas.predictions", "qualname": "CategoryEnum.Grocery", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;CategoryEnum.Grocery: &#x27;Grocery&#x27;&gt;"}, {"fullname": "src.inference.api.schemas.predictions.CategoryEnum.Health_and_Personal_Care", "modulename": "src.inference.api.schemas.predictions", "qualname": "CategoryEnum.Health_and_Personal_Care", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;CategoryEnum.Health_and_Personal_Care: &#x27;Health &amp; Personal Care&#x27;&gt;"}, {"fullname": "src.inference.api.schemas.predictions.CategoryEnum.Home_Audio_and_Theater", "modulename": "src.inference.api.schemas.predictions", "qualname": "CategoryEnum.Home_Audio_and_Theater", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;CategoryEnum.Home_Audio_and_Theater: &#x27;Home Audio &amp; Theater&#x27;&gt;"}, {"fullname": "src.inference.api.schemas.predictions.CategoryEnum.Industrial_and_Scientific", "modulename": "src.inference.api.schemas.predictions", "qualname": "CategoryEnum.Industrial_and_Scientific", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;CategoryEnum.Industrial_and_Scientific: &#x27;Industrial &amp; Scientific&#x27;&gt;"}, {"fullname": "src.inference.api.schemas.predictions.CategoryEnum.Movies_and_TV", "modulename": "src.inference.api.schemas.predictions", "qualname": "CategoryEnum.Movies_and_TV", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;CategoryEnum.Movies_and_TV: &#x27;Movies &amp; TV&#x27;&gt;"}, {"fullname": "src.inference.api.schemas.predictions.CategoryEnum.Musical_Instruments", "modulename": "src.inference.api.schemas.predictions", "qualname": "CategoryEnum.Musical_Instruments", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;CategoryEnum.Musical_Instruments: &#x27;Musical Instruments&#x27;&gt;"}, {"fullname": "src.inference.api.schemas.predictions.CategoryEnum.Office_Products", "modulename": "src.inference.api.schemas.predictions", "qualname": "CategoryEnum.Office_Products", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;CategoryEnum.Office_Products: &#x27;Office Products&#x27;&gt;"}, {"fullname": "src.inference.api.schemas.predictions.CategoryEnum.Pet_Supplies", "modulename": "src.inference.api.schemas.predictions", "qualname": "CategoryEnum.Pet_Supplies", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;CategoryEnum.Pet_Supplies: &#x27;Pet Supplies&#x27;&gt;"}, {"fullname": "src.inference.api.schemas.predictions.CategoryEnum.Sports_and_Outdoors", "modulename": "src.inference.api.schemas.predictions", "qualname": "CategoryEnum.Sports_and_Outdoors", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;CategoryEnum.Sports_and_Outdoors: &#x27;Sports &amp; Outdoors&#x27;&gt;"}, {"fullname": "src.inference.api.schemas.predictions.CategoryEnum.Tools_and_Home_Improvement", "modulename": "src.inference.api.schemas.predictions", "qualname": "CategoryEnum.Tools_and_Home_Improvement", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;CategoryEnum.Tools_and_Home_Improvement: &#x27;Tools &amp; Home Improvement&#x27;&gt;"}, {"fullname": "src.inference.api.schemas.predictions.CategoryEnum.Toys_and_Games", "modulename": "src.inference.api.schemas.predictions", "qualname": "CategoryEnum.Toys_and_Games", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;CategoryEnum.Toys_and_Games: &#x27;Toys &amp; Games&#x27;&gt;"}, {"fullname": "src.inference.api.schemas.predictions.CategoryEnum.Video_Games", "modulename": "src.inference.api.schemas.predictions", "qualname": "CategoryEnum.Video_Games", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;CategoryEnum.Video_Games: &#x27;Video Games&#x27;&gt;"}, {"fullname": "src.inference.api.schemas.predictions.PredictionResponse", "modulename": "src.inference.api.schemas.predictions", "qualname": "PredictionResponse", "kind": "class", "doc": "<p>Pydantic schema for the predictions response.</p>\n\n<p>Attributes:\n    main_cat (CategoryEnum): The predicted category.</p>\n", "bases": "pydantic.main.BaseModel"}, {"fullname": "src.inference.api.schemas.predictions.PredictionResponse.main_cat", "modulename": "src.inference.api.schemas.predictions", "qualname": "PredictionResponse.main_cat", "kind": "variable", "doc": "<p></p>\n", "annotation": ": src.inference.api.schemas.predictions.CategoryEnum"}, {"fullname": "src.inference.api.schemas.predictions.PredictionResponse.model_config", "modulename": "src.inference.api.schemas.predictions", "qualname": "PredictionResponse.model_config", "kind": "variable", "doc": "<p></p>\n", "default_value": "{}"}, {"fullname": "src.inference.api.schemas.predictions.PredictionResponse.model_fields", "modulename": "src.inference.api.schemas.predictions", "qualname": "PredictionResponse.model_fields", "kind": "variable", "doc": "<p></p>\n", "default_value": "{&#x27;main_cat&#x27;: FieldInfo(annotation=CategoryEnum, required=True)}"}, {"fullname": "src.inference.api.schemas.product_descriptions", "modulename": "src.inference.api.schemas.product_descriptions", "kind": "module", "doc": "<p>Module for Pydantic schema used in the API for input data.</p>\n"}, {"fullname": "src.inference.api.schemas.product_descriptions.ProductDescription", "modulename": "src.inference.api.schemas.product_descriptions", "qualname": "ProductDescription", "kind": "class", "doc": "<p>Pydantic model for the expected input product description.</p>\n\n<p>Attributes:\n    also_buy (list[str]): List of also bought products.\n    also_view (list[str]): List of also viewed products.\n    asin (str): Amazon Standard Identification Number.\n    brand (str): Brand of the product.\n    category (list[str]): List of categories the product belongs to.\n    description (list[str]): List of product descriptions.\n    feature (list[str]): List of product features.\n    image (list[str]): List of image URLs.\n    price (str): Price of the product.\n    title (str): Title of the product.</p>\n", "bases": "pydantic.main.BaseModel"}, {"fullname": "src.inference.api.schemas.product_descriptions.ProductDescription.also_buy", "modulename": "src.inference.api.schemas.product_descriptions", "qualname": "ProductDescription.also_buy", "kind": "variable", "doc": "<p></p>\n", "annotation": ": list[str]"}, {"fullname": "src.inference.api.schemas.product_descriptions.ProductDescription.also_view", "modulename": "src.inference.api.schemas.product_descriptions", "qualname": "ProductDescription.also_view", "kind": "variable", "doc": "<p></p>\n", "annotation": ": list[str]"}, {"fullname": "src.inference.api.schemas.product_descriptions.ProductDescription.asin", "modulename": "src.inference.api.schemas.product_descriptions", "qualname": "ProductDescription.asin", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "src.inference.api.schemas.product_descriptions.ProductDescription.brand", "modulename": "src.inference.api.schemas.product_descriptions", "qualname": "ProductDescription.brand", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "src.inference.api.schemas.product_descriptions.ProductDescription.category", "modulename": "src.inference.api.schemas.product_descriptions", "qualname": "ProductDescription.category", "kind": "variable", "doc": "<p></p>\n", "annotation": ": list[str]"}, {"fullname": "src.inference.api.schemas.product_descriptions.ProductDescription.description", "modulename": "src.inference.api.schemas.product_descriptions", "qualname": "ProductDescription.description", "kind": "variable", "doc": "<p></p>\n", "annotation": ": list[str]"}, {"fullname": "src.inference.api.schemas.product_descriptions.ProductDescription.feature", "modulename": "src.inference.api.schemas.product_descriptions", "qualname": "ProductDescription.feature", "kind": "variable", "doc": "<p></p>\n", "annotation": ": list[str]"}, {"fullname": "src.inference.api.schemas.product_descriptions.ProductDescription.image", "modulename": "src.inference.api.schemas.product_descriptions", "qualname": "ProductDescription.image", "kind": "variable", "doc": "<p></p>\n", "annotation": ": list[str]"}, {"fullname": "src.inference.api.schemas.product_descriptions.ProductDescription.price", "modulename": "src.inference.api.schemas.product_descriptions", "qualname": "ProductDescription.price", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "src.inference.api.schemas.product_descriptions.ProductDescription.title", "modulename": "src.inference.api.schemas.product_descriptions", "qualname": "ProductDescription.title", "kind": "variable", "doc": "<p></p>\n", "annotation": ": str"}, {"fullname": "src.inference.api.schemas.product_descriptions.ProductDescription.model_config", "modulename": "src.inference.api.schemas.product_descriptions", "qualname": "ProductDescription.model_config", "kind": "variable", "doc": "<p></p>\n", "default_value": "{}"}, {"fullname": "src.inference.api.schemas.product_descriptions.ProductDescription.model_fields", "modulename": "src.inference.api.schemas.product_descriptions", "qualname": "ProductDescription.model_fields", "kind": "variable", "doc": "<p></p>\n", "default_value": "{&#x27;also_buy&#x27;: FieldInfo(annotation=list[str], required=True), &#x27;also_view&#x27;: FieldInfo(annotation=list[str], required=True), &#x27;asin&#x27;: FieldInfo(annotation=str, required=True), &#x27;brand&#x27;: FieldInfo(annotation=str, required=True), &#x27;category&#x27;: FieldInfo(annotation=list[str], required=True), &#x27;description&#x27;: FieldInfo(annotation=list[str], required=True), &#x27;feature&#x27;: FieldInfo(annotation=list[str], required=True), &#x27;image&#x27;: FieldInfo(annotation=list[str], required=True), &#x27;price&#x27;: FieldInfo(annotation=str, required=True), &#x27;title&#x27;: FieldInfo(annotation=str, required=True)}"}, {"fullname": "src.inference.settings", "modulename": "src.inference.settings", "kind": "module", "doc": "<p>Module for setting up the environment.</p>\n"}, {"fullname": "src.inference.settings.load_env_vars", "modulename": "src.inference.settings", "qualname": "load_env_vars", "kind": "function", "doc": "<p>Load environment variables from .env file.</p>\n\n<p>Returns:\n    dict[str]: Environment variables.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"nb\">dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.inference.settings.SETTINGS", "modulename": "src.inference.settings", "qualname": "SETTINGS", "kind": "variable", "doc": "<p></p>\n", "default_value": "{&#x27;SHELL&#x27;: &#x27;/bin/bash&#x27;, &#x27;SESSION_MANAGER&#x27;: &#x27;local/victor-ubuntu:@/tmp/.ICE-unix/4146,unix/victor-ubuntu:/tmp/.ICE-unix/4146&#x27;, &#x27;QT_ACCESSIBILITY&#x27;: &#x27;1&#x27;, &#x27;COLORTERM&#x27;: &#x27;truecolor&#x27;, &#x27;XDG_CONFIG_DIRS&#x27;: &#x27;/etc/xdg/xdg-ubuntu:/etc/xdg&#x27;, &#x27;SSH_AGENT_LAUNCHER&#x27;: &#x27;gnome-keyring&#x27;, &#x27;NVM_INC&#x27;: &#x27;/home/victor/.nvm/versions/node/v18.19.0/include/node&#x27;, &#x27;XDG_MENU_PREFIX&#x27;: &#x27;gnome-&#x27;, &#x27;TERM_PROGRAM_VERSION&#x27;: &#x27;1.90.1&#x27;, &#x27;GNOME_DESKTOP_SESSION_ID&#x27;: &#x27;this-is-deprecated&#x27;, &#x27;CONDA_EXE&#x27;: &#x27;/home/victor/anaconda3/bin/conda&#x27;, &#x27;_CE_M&#x27;: &#x27;&#x27;, &#x27;VSCODE_INSPECTOR_OPTIONS&#x27;: &#x27;:::{&quot;inspectorIpc&quot;:&quot;/tmp/node-cdp.66032-b1f14bfe-0.sock.deferred&quot;,&quot;deferredMode&quot;:true,&quot;waitForDebugger&quot;:&quot;&quot;,&quot;execPath&quot;:&quot;/home/victor/.nvm/versions/node/v18.19.0/bin/node&quot;,&quot;onlyEntrypoint&quot;:false,&quot;autoAttachMode&quot;:&quot;always&quot;}&#x27;, &#x27;LANGUAGE&#x27;: &#x27;en&#x27;, &#x27;NODE_OPTIONS&#x27;: &#x27; --require /home/victor/.config/Code/User/workspaceStorage/2581da840a2a318fa549befac873e5fb/ms-vscode.js-debug/bootloader.js &#x27;, &#x27;MANDATORY_PATH&#x27;: &#x27;/usr/share/gconf/ubuntu.mandatory.path&#x27;, &#x27;LC_ADDRESS&#x27;: &#x27;es_ES.UTF-8&#x27;, &#x27;GNOME_SHELL_SESSION_MODE&#x27;: &#x27;ubuntu&#x27;, &#x27;LC_NAME&#x27;: &#x27;es_ES.UTF-8&#x27;, &#x27;SSH_AUTH_SOCK&#x27;: &#x27;/run/user/1000/keyring/ssh&#x27;, &#x27;XMODIFIERS&#x27;: &#x27;@im=ibus&#x27;, &#x27;DESKTOP_SESSION&#x27;: &#x27;ubuntu&#x27;, &#x27;LC_MONETARY&#x27;: &#x27;es_ES.UTF-8&#x27;, &#x27;GTK_MODULES&#x27;: &#x27;gail:atk-bridge&#x27;, &#x27;PWD&#x27;: &#x27;/home/victor/fever/code_challenge/victor_martinez&#x27;, &#x27;XDG_SESSION_DESKTOP&#x27;: &#x27;ubuntu&#x27;, &#x27;LOGNAME&#x27;: &#x27;victor&#x27;, &#x27;CONDA_ROOT&#x27;: &#x27;/home/victor/anaconda3&#x27;, &#x27;XDG_SESSION_TYPE&#x27;: &#x27;x11&#x27;, &#x27;CONDA_PREFIX&#x27;: &#x27;/home/victor/anaconda3/envs/training&#x27;, &#x27;GPG_AGENT_INFO&#x27;: &#x27;/run/user/1000/gnupg/S.gpg-agent:0:1&#x27;, &#x27;SYSTEMD_EXEC_PID&#x27;: &#x27;4172&#x27;, &#x27;XAUTHORITY&#x27;: &#x27;/run/user/1000/gdm/Xauthority&#x27;, &#x27;VSCODE_GIT_ASKPASS_NODE&#x27;: &#x27;/usr/share/code/code&#x27;, &#x27;GJS_DEBUG_TOPICS&#x27;: &#x27;JS ERROR;JS LOG&#x27;, &#x27;WINDOWPATH&#x27;: &#x27;2&#x27;, &#x27;HOME&#x27;: &#x27;/home/victor&#x27;, &#x27;USERNAME&#x27;: &#x27;victor&#x27;, &#x27;IM_CONFIG_PHASE&#x27;: &#x27;1&#x27;, &#x27;LC_PAPER&#x27;: &#x27;es_ES.UTF-8&#x27;, &#x27;LANG&#x27;: &#x27;en_US.UTF-8&#x27;, &#x27;LS_COLORS&#x27;: &#x27;rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.webp=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:&#x27;, &#x27;XDG_CURRENT_DESKTOP&#x27;: &#x27;Unity&#x27;, &#x27;CONDA_PROMPT_MODIFIER&#x27;: &#x27;(training) &#x27;, &#x27;GIT_ASKPASS&#x27;: &#x27;/usr/share/code/resources/app/extensions/git/dist/askpass.sh&#x27;, &#x27;INVOCATION_ID&#x27;: &#x27;3573a86428f24f94957b4bbb7f7351ea&#x27;, &#x27;MANAGERPID&#x27;: &#x27;3684&#x27;, &#x27;CHROME_DESKTOP&#x27;: &#x27;code-url-handler.desktop&#x27;, &#x27;GJS_DEBUG_OUTPUT&#x27;: &#x27;stderr&#x27;, &#x27;NVM_DIR&#x27;: &#x27;/home/victor/.nvm&#x27;, &#x27;VSCODE_GIT_ASKPASS_EXTRA_ARGS&#x27;: &#x27;&#x27;, &#x27;LESSCLOSE&#x27;: &#x27;/usr/bin/lesspipe %s %s&#x27;, &#x27;XDG_SESSION_CLASS&#x27;: &#x27;user&#x27;, &#x27;TERM&#x27;: &#x27;xterm-256color&#x27;, &#x27;LC_IDENTIFICATION&#x27;: &#x27;es_ES.UTF-8&#x27;, &#x27;_CE_CONDA&#x27;: &#x27;&#x27;, &#x27;DEFAULTS_PATH&#x27;: &#x27;/usr/share/gconf/ubuntu.default.path&#x27;, &#x27;LESSOPEN&#x27;: &#x27;| /usr/bin/lesspipe %s&#x27;, &#x27;USER&#x27;: &#x27;victor&#x27;, &#x27;VSCODE_GIT_IPC_HANDLE&#x27;: &#x27;/run/user/1000/vscode-git-f3531e9239.sock&#x27;, &#x27;CONDA_SHLVL&#x27;: &#x27;2&#x27;, &#x27;DISPLAY&#x27;: &#x27;:1&#x27;, &#x27;SHLVL&#x27;: &#x27;1&#x27;, &#x27;NVM_CD_FLAGS&#x27;: &#x27;&#x27;, &#x27;LC_TELEPHONE&#x27;: &#x27;es_ES.UTF-8&#x27;, &#x27;QT_IM_MODULE&#x27;: &#x27;ibus&#x27;, &#x27;LC_MEASUREMENT&#x27;: &#x27;es_ES.UTF-8&#x27;, &#x27;PAPERSIZE&#x27;: &#x27;a4&#x27;, &#x27;CONDA_PYTHON_EXE&#x27;: &#x27;/home/victor/anaconda3/bin/python&#x27;, &#x27;XDG_RUNTIME_DIR&#x27;: &#x27;/run/user/1000&#x27;, &#x27;PS1&#x27;: &#x27;\\\\[\\x1b]633;A\\x07\\\\](training) (base) \\\\[\\\\e]0;\\\\u@\\\\h: \\\\w\\\\a\\\\]${debian_chroot:+($debian_chroot)}\\\\[\\\\033[01;32m\\\\]\\\\u@\\\\h\\\\[\\\\033[00m\\\\]:\\\\[\\\\033[01;34m\\\\]\\\\w\\\\[\\\\033[00m\\\\]\\\\$ \\\\[\\x1b]633;B\\x07\\\\]&#x27;, &#x27;CONDA_DEFAULT_ENV&#x27;: &#x27;training&#x27;, &#x27;LC_TIME&#x27;: &#x27;es_ES.UTF-8&#x27;, &#x27;VSCODE_GIT_ASKPASS_MAIN&#x27;: &#x27;/usr/share/code/resources/app/extensions/git/dist/askpass-main.js&#x27;, &#x27;JOURNAL_STREAM&#x27;: &#x27;8:49172&#x27;, &#x27;XDG_DATA_DIRS&#x27;: &#x27;/usr/share/ubuntu:/usr/share/gnome:/usr/local/share/:/usr/share/:/var/lib/snapd/desktop&#x27;, &#x27;GDK_BACKEND&#x27;: &#x27;x11&#x27;, &#x27;PATH&#x27;: &#x27;/home/victor/.local/bin:/opt/cmake/bin:/home/victor/anaconda3/envs/training/bin:/home/victor/anaconda3/condabin:/home/victor/.nvm/versions/node/v18.19.0/bin:/home/victor/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/snap/bin:/opt/cmake/bin:/home/victor/.nvm/versions/node/v18.19.0/bin:/home/victor/.local/bin:/opt/cmake/bin:/home/victor/anaconda3/bin:/home/victor/anaconda3/condabin:/home/victor/.nvm/versions/node/v18.19.0/bin:/home/victor/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/snap/bin:/home/victor/.local/bin:/opt/cmake/bin:/home/victor/anaconda3/bin:/home/victor/anaconda3/condabin:/home/victor/.nvm/versions/node/v18.19.0/bin:/home/victor/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/snap/bin&#x27;, &#x27;GDMSESSION&#x27;: &#x27;ubuntu&#x27;, &#x27;ORIGINAL_XDG_CURRENT_DESKTOP&#x27;: &#x27;ubuntu:GNOME&#x27;, &#x27;DBUS_SESSION_BUS_ADDRESS&#x27;: &#x27;unix:path=/run/user/1000/bus&#x27;, &#x27;NVM_BIN&#x27;: &#x27;/home/victor/.nvm/versions/node/v18.19.0/bin&#x27;, &#x27;CONDA_PREFIX_1&#x27;: &#x27;/home/victor/anaconda3&#x27;, &#x27;CONDA_PREFIX_2&#x27;: &#x27;/home/victor/anaconda3/envs/training&#x27;, &#x27;GIO_LAUNCHED_DESKTOP_FILE_PID&#x27;: &#x27;8409&#x27;, &#x27;GIO_LAUNCHED_DESKTOP_FILE&#x27;: &#x27;/usr/share/applications/code.desktop&#x27;, &#x27;LC_NUMERIC&#x27;: &#x27;es_ES.UTF-8&#x27;, &#x27;TERM_PROGRAM&#x27;: &#x27;vscode&#x27;, &#x27;_&#x27;: &#x27;/home/victor/anaconda3/envs/training/bin/pdoc&#x27;, &#x27;KMP_DUPLICATE_LIB_OK&#x27;: &#x27;True&#x27;, &#x27;KMP_INIT_AT_FORK&#x27;: &#x27;FALSE&#x27;, &#x27;TOKENIZERS_PARALLELISM&#x27;: &#x27;false&#x27;, &#x27;MLFLOW_TRACKING_URI&#x27;: &#x27;databricks&#x27;, &#x27;MLFLOW_EXPERIMENT_NAME&#x27;: &#x27;/fever-code-challenge&#x27;, &#x27;MLFLOW_RUN_ID&#x27;: &#x27;b4c9bfbb6abf475f8ad2c9a3688312a0&#x27;}"}, {"fullname": "src.inference.utils", "modulename": "src.inference.utils", "kind": "module", "doc": "<p>Module for utility functions.</p>\n"}, {"fullname": "src.inference.utils.get_logger", "modulename": "src.inference.utils", "qualname": "get_logger", "kind": "function", "doc": "<p>Template for getting a logger.</p>\n\n<p>Args:\n    name: Name of the logger.</p>\n\n<p>Returns: Logger.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">Logger</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.inference.utils.preprocess_data", "modulename": "src.inference.utils", "qualname": "preprocess_data", "kind": "function", "doc": "<p>Preprocesses the input data for the model.</p>\n\n<p>Args:\n    data (ProductDescription): The input data to preprocess.</p>\n\n<p>Returns:\n    str: The preprocessed text data.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">data</span><span class=\"p\">:</span> <span class=\"n\">src</span><span class=\"o\">.</span><span class=\"n\">inference</span><span class=\"o\">.</span><span class=\"n\">api</span><span class=\"o\">.</span><span class=\"n\">schemas</span><span class=\"o\">.</span><span class=\"n\">product_descriptions</span><span class=\"o\">.</span><span class=\"n\">ProductDescription</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">str</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.training", "modulename": "src.training", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.training.constants", "modulename": "src.training.constants", "kind": "module", "doc": "<p>Module with constants used in the training pipeline.</p>\n\n<p>Attributes:\n    CATEGORIES (list[str]): List of possible product categories.</p>\n"}, {"fullname": "src.training.constants.CATEGORIES", "modulename": "src.training.constants", "qualname": "CATEGORIES", "kind": "variable", "doc": "<p></p>\n", "default_value": "[&#x27;All Electronics&#x27;, &#x27;Amazon Fashion&#x27;, &#x27;Amazon Home&#x27;, &#x27;Arts, Crafts &amp; Sewing&#x27;, &#x27;Automotive&#x27;, &#x27;Books&#x27;, &#x27;Camera &amp; Photo&#x27;, &#x27;Cell Phones &amp; Accessories&#x27;, &#x27;Computers&#x27;, &#x27;Digital Music&#x27;, &#x27;Grocery&#x27;, &#x27;Health &amp; Personal Care&#x27;, &#x27;Home Audio &amp; Theater&#x27;, &#x27;Industrial &amp; Scientific&#x27;, &#x27;Movies &amp; TV&#x27;, &#x27;Musical Instruments&#x27;, &#x27;Office Products&#x27;, &#x27;Pet Supplies&#x27;, &#x27;Sports &amp; Outdoors&#x27;, &#x27;Tools &amp; Home Improvement&#x27;, &#x27;Toys &amp; Games&#x27;, &#x27;Video Games&#x27;]"}, {"fullname": "src.training.datasets", "modulename": "src.training.datasets", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.training.datasets.product_dataset", "modulename": "src.training.datasets.product_dataset", "kind": "module", "doc": "<p>Module that defines the PyTorch IterableDataset for the product data.</p>\n"}, {"fullname": "src.training.datasets.product_dataset.logger", "modulename": "src.training.datasets.product_dataset", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger src.training.datasets.product_dataset (INFO)&gt;"}, {"fullname": "src.training.datasets.product_dataset.ProductIterableDataset", "modulename": "src.training.datasets.product_dataset", "qualname": "ProductIterableDataset", "kind": "class", "doc": "<p>PyTorch IterableDataset for product data.</p>\n\n<p>Attributes:\n    df (DataFrame): The Spark DataFrame containing the data.\n    label_encoder (LabelEncoder): An encoder for converting category labels to integers.\n    tokenizer (BertTokenizer): The BERT tokenizer to use.\n    encoded (bool): Whether the data is already encoded or not.\n    max_length (int): Maximum length of the input sequence for BERT Tokenizer. Defaults to 512.</p>\n", "bases": "torch.utils.data.dataset.Dataset[+T_co], typing.Iterable[+T_co]"}, {"fullname": "src.training.datasets.product_dataset.ProductIterableDataset.__init__", "modulename": "src.training.datasets.product_dataset", "qualname": "ProductIterableDataset.__init__", "kind": "function", "doc": "<p>Initializes the dataset with a Spark DataFrame, a label encoder, and a tokenizer.</p>\n\n<p>Args:\n    df (DataFrame): The Spark DataFrame to load data from.\n    label_encoder (LabelEncoder): The encoder for converting category labels to integers.\n    tokenizer (BertTokenizer): The BERT tokenizer to use.\n    encoded (bool): Whether the data is already encoded or not.\n    max_length (int): Maximum length of the input sequence for BERT Tokenizer. Defaults to 512.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">df</span><span class=\"p\">:</span> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>,</span><span class=\"param\">\t<span class=\"n\">label_encoder</span><span class=\"p\">:</span> <span class=\"n\">sklearn</span><span class=\"o\">.</span><span class=\"n\">preprocessing</span><span class=\"o\">.</span><span class=\"n\">_label</span><span class=\"o\">.</span><span class=\"n\">LabelEncoder</span>,</span><span class=\"param\">\t<span class=\"n\">tokenizer</span><span class=\"p\">:</span> <span class=\"n\">transformers</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">auto</span><span class=\"o\">.</span><span class=\"n\">tokenization_auto</span><span class=\"o\">.</span><span class=\"n\">AutoTokenizer</span>,</span><span class=\"param\">\t<span class=\"n\">encoded</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">max_length</span><span class=\"o\">=</span><span class=\"mi\">512</span></span>)</span>"}, {"fullname": "src.training.datasets.product_dataset.ProductIterableDataset.df", "modulename": "src.training.datasets.product_dataset", "qualname": "ProductIterableDataset.df", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.training.datasets.product_dataset.ProductIterableDataset.label_encoder", "modulename": "src.training.datasets.product_dataset", "qualname": "ProductIterableDataset.label_encoder", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.training.datasets.product_dataset.ProductIterableDataset.tokenizer", "modulename": "src.training.datasets.product_dataset", "qualname": "ProductIterableDataset.tokenizer", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.training.datasets.product_dataset.ProductIterableDataset.encoded", "modulename": "src.training.datasets.product_dataset", "qualname": "ProductIterableDataset.encoded", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.training.datasets.product_dataset.ProductIterableDataset.max_length", "modulename": "src.training.datasets.product_dataset", "qualname": "ProductIterableDataset.max_length", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.training.datasets.product_dataset.ProductIterableDataset.reshuffle", "modulename": "src.training.datasets.product_dataset", "qualname": "ProductIterableDataset.reshuffle", "kind": "function", "doc": "<p>Reshuffles the DataFrame.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"mi\">42</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.datasets.product_dataset.ProductIterableDataset.process_row", "modulename": "src.training.datasets.product_dataset", "qualname": "ProductIterableDataset.process_row", "kind": "function", "doc": "<p>Processes a single row of the DataFrame.</p>\n\n<p>Args:\n    row: A row from DataFrame.</p>\n\n<p>Returns:\n    tuple containing input_ids, attention_mask, and label as tensors.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">row</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.training.datasets.product_dataset.ProductIterableDataset.process_encoded_row", "modulename": "src.training.datasets.product_dataset", "qualname": "ProductIterableDataset.process_encoded_row", "kind": "function", "doc": "<p>Processes a single row of the DataFrame that is already encoded.</p>\n\n<p>Args:\n    row: A row from DataFrame.</p>\n\n<p>Returns:\n    tuple containing input_ids, attention_mask, and label as tensors.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"bp\">self</span>, </span><span class=\"param\"><span class=\"n\">row</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">Tensor</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.training.datasets.product_dataset.ProductDataset", "modulename": "src.training.datasets.product_dataset", "qualname": "ProductDataset", "kind": "class", "doc": "<p>PyTorch Dataset for product data.</p>\n\n<p>Attributes:\n    df (pd.DataFrame): The pandas DataFrame containing the data.\n    label_encoder (LabelEncoder): An encoder for converting category labels to integers.\n    tokenizer (AutoTokenizer): The BERT tokenizer to use.\n    encoded (bool): Whether the data is already encoded or not.\n    max_length (int): Maximum length of the input sequence for BERT Tokenizer. Defaults to 512.</p>\n", "bases": "typing.Generic[+T_co]"}, {"fullname": "src.training.datasets.product_dataset.ProductDataset.__init__", "modulename": "src.training.datasets.product_dataset", "qualname": "ProductDataset.__init__", "kind": "function", "doc": "<p>Initializes the dataset with a pandas DataFrame, a label encoder, and a tokenizer.</p>\n\n<p>Args:\n    df (pd.DataFrame): The pandas DataFrame to load data from.\n    label_encoder (LabelEncoder): The encoder for converting category labels to integers.\n    tokenizer (AutoTokenizer): The BERT tokenizer to use.\n    encoded (bool): Whether the data is already encoded or not.\n    max_length (int): Maximum length of the input sequence for BERT Tokenizer. Defaults to 512.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">df</span><span class=\"p\">:</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>,</span><span class=\"param\">\t<span class=\"n\">label_encoder</span><span class=\"p\">:</span> <span class=\"n\">sklearn</span><span class=\"o\">.</span><span class=\"n\">preprocessing</span><span class=\"o\">.</span><span class=\"n\">_label</span><span class=\"o\">.</span><span class=\"n\">LabelEncoder</span>,</span><span class=\"param\">\t<span class=\"n\">tokenizer</span><span class=\"p\">:</span> <span class=\"n\">transformers</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">auto</span><span class=\"o\">.</span><span class=\"n\">tokenization_auto</span><span class=\"o\">.</span><span class=\"n\">AutoTokenizer</span>,</span><span class=\"param\">\t<span class=\"n\">encoded</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">max_length</span><span class=\"o\">=</span><span class=\"mi\">512</span></span>)</span>"}, {"fullname": "src.training.datasets.product_dataset.ProductDataset.df", "modulename": "src.training.datasets.product_dataset", "qualname": "ProductDataset.df", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.training.datasets.product_dataset.ProductDataset.label_encoder", "modulename": "src.training.datasets.product_dataset", "qualname": "ProductDataset.label_encoder", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.training.datasets.product_dataset.ProductDataset.tokenizer", "modulename": "src.training.datasets.product_dataset", "qualname": "ProductDataset.tokenizer", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.training.datasets.product_dataset.ProductDataset.encoded", "modulename": "src.training.datasets.product_dataset", "qualname": "ProductDataset.encoded", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.training.datasets.product_dataset.ProductDataset.max_length", "modulename": "src.training.datasets.product_dataset", "qualname": "ProductDataset.max_length", "kind": "variable", "doc": "<p></p>\n"}, {"fullname": "src.training.datasets.product_dataset.ProductDataset.process_row", "modulename": "src.training.datasets.product_dataset", "qualname": "ProductDataset.process_row", "kind": "function", "doc": "<p>Processes a single row of the DataFrame.</p>\n\n<p>Args:\n    row: A row from DataFrame.</p>\n\n<p>Returns:\n    tuple containing input_ids, attention_mask, and label as tensors.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"bp\">self</span>,</span><span class=\"param\">\t<span class=\"n\">row</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">_VariableFunctionsClass</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">_VariableFunctionsClass</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">_VariableFunctionsClass</span><span class=\"o\">.</span><span class=\"n\">tensor</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.training.settings", "modulename": "src.training.settings", "kind": "module", "doc": "<p>Module for setting up the environment.</p>\n"}, {"fullname": "src.training.settings.load_env_vars", "modulename": "src.training.settings", "qualname": "load_env_vars", "kind": "function", "doc": "<p>Load environment variables from .env file.</p>\n\n<p>Returns:\n    dict[str]: Environment variables.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"return-annotation\">) -> <span class=\"nb\">dict</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.training.settings.SETTINGS", "modulename": "src.training.settings", "qualname": "SETTINGS", "kind": "variable", "doc": "<p></p>\n", "default_value": "{&#x27;SHELL&#x27;: &#x27;/bin/bash&#x27;, &#x27;SESSION_MANAGER&#x27;: &#x27;local/victor-ubuntu:@/tmp/.ICE-unix/4146,unix/victor-ubuntu:/tmp/.ICE-unix/4146&#x27;, &#x27;QT_ACCESSIBILITY&#x27;: &#x27;1&#x27;, &#x27;COLORTERM&#x27;: &#x27;truecolor&#x27;, &#x27;XDG_CONFIG_DIRS&#x27;: &#x27;/etc/xdg/xdg-ubuntu:/etc/xdg&#x27;, &#x27;SSH_AGENT_LAUNCHER&#x27;: &#x27;gnome-keyring&#x27;, &#x27;NVM_INC&#x27;: &#x27;/home/victor/.nvm/versions/node/v18.19.0/include/node&#x27;, &#x27;XDG_MENU_PREFIX&#x27;: &#x27;gnome-&#x27;, &#x27;TERM_PROGRAM_VERSION&#x27;: &#x27;1.90.1&#x27;, &#x27;GNOME_DESKTOP_SESSION_ID&#x27;: &#x27;this-is-deprecated&#x27;, &#x27;CONDA_EXE&#x27;: &#x27;/home/victor/anaconda3/bin/conda&#x27;, &#x27;_CE_M&#x27;: &#x27;&#x27;, &#x27;VSCODE_INSPECTOR_OPTIONS&#x27;: &#x27;:::{&quot;inspectorIpc&quot;:&quot;/tmp/node-cdp.66032-b1f14bfe-0.sock.deferred&quot;,&quot;deferredMode&quot;:true,&quot;waitForDebugger&quot;:&quot;&quot;,&quot;execPath&quot;:&quot;/home/victor/.nvm/versions/node/v18.19.0/bin/node&quot;,&quot;onlyEntrypoint&quot;:false,&quot;autoAttachMode&quot;:&quot;always&quot;}&#x27;, &#x27;LANGUAGE&#x27;: &#x27;en&#x27;, &#x27;NODE_OPTIONS&#x27;: &#x27; --require /home/victor/.config/Code/User/workspaceStorage/2581da840a2a318fa549befac873e5fb/ms-vscode.js-debug/bootloader.js &#x27;, &#x27;MANDATORY_PATH&#x27;: &#x27;/usr/share/gconf/ubuntu.mandatory.path&#x27;, &#x27;LC_ADDRESS&#x27;: &#x27;es_ES.UTF-8&#x27;, &#x27;GNOME_SHELL_SESSION_MODE&#x27;: &#x27;ubuntu&#x27;, &#x27;LC_NAME&#x27;: &#x27;es_ES.UTF-8&#x27;, &#x27;SSH_AUTH_SOCK&#x27;: &#x27;/run/user/1000/keyring/ssh&#x27;, &#x27;XMODIFIERS&#x27;: &#x27;@im=ibus&#x27;, &#x27;DESKTOP_SESSION&#x27;: &#x27;ubuntu&#x27;, &#x27;LC_MONETARY&#x27;: &#x27;es_ES.UTF-8&#x27;, &#x27;GTK_MODULES&#x27;: &#x27;gail:atk-bridge&#x27;, &#x27;PWD&#x27;: &#x27;/home/victor/fever/code_challenge/victor_martinez&#x27;, &#x27;XDG_SESSION_DESKTOP&#x27;: &#x27;ubuntu&#x27;, &#x27;LOGNAME&#x27;: &#x27;victor&#x27;, &#x27;CONDA_ROOT&#x27;: &#x27;/home/victor/anaconda3&#x27;, &#x27;XDG_SESSION_TYPE&#x27;: &#x27;x11&#x27;, &#x27;CONDA_PREFIX&#x27;: &#x27;/home/victor/anaconda3/envs/training&#x27;, &#x27;GPG_AGENT_INFO&#x27;: &#x27;/run/user/1000/gnupg/S.gpg-agent:0:1&#x27;, &#x27;SYSTEMD_EXEC_PID&#x27;: &#x27;4172&#x27;, &#x27;XAUTHORITY&#x27;: &#x27;/run/user/1000/gdm/Xauthority&#x27;, &#x27;VSCODE_GIT_ASKPASS_NODE&#x27;: &#x27;/usr/share/code/code&#x27;, &#x27;GJS_DEBUG_TOPICS&#x27;: &#x27;JS ERROR;JS LOG&#x27;, &#x27;WINDOWPATH&#x27;: &#x27;2&#x27;, &#x27;HOME&#x27;: &#x27;/home/victor&#x27;, &#x27;USERNAME&#x27;: &#x27;victor&#x27;, &#x27;IM_CONFIG_PHASE&#x27;: &#x27;1&#x27;, &#x27;LC_PAPER&#x27;: &#x27;es_ES.UTF-8&#x27;, &#x27;LANG&#x27;: &#x27;en_US.UTF-8&#x27;, &#x27;LS_COLORS&#x27;: &#x27;rs=0:di=01;34:ln=01;36:mh=00:pi=40;33:so=01;35:do=01;35:bd=40;33;01:cd=40;33;01:or=40;31;01:mi=00:su=37;41:sg=30;43:ca=30;41:tw=30;42:ow=34;42:st=37;44:ex=01;32:*.tar=01;31:*.tgz=01;31:*.arc=01;31:*.arj=01;31:*.taz=01;31:*.lha=01;31:*.lz4=01;31:*.lzh=01;31:*.lzma=01;31:*.tlz=01;31:*.txz=01;31:*.tzo=01;31:*.t7z=01;31:*.zip=01;31:*.z=01;31:*.dz=01;31:*.gz=01;31:*.lrz=01;31:*.lz=01;31:*.lzo=01;31:*.xz=01;31:*.zst=01;31:*.tzst=01;31:*.bz2=01;31:*.bz=01;31:*.tbz=01;31:*.tbz2=01;31:*.tz=01;31:*.deb=01;31:*.rpm=01;31:*.jar=01;31:*.war=01;31:*.ear=01;31:*.sar=01;31:*.rar=01;31:*.alz=01;31:*.ace=01;31:*.zoo=01;31:*.cpio=01;31:*.7z=01;31:*.rz=01;31:*.cab=01;31:*.wim=01;31:*.swm=01;31:*.dwm=01;31:*.esd=01;31:*.jpg=01;35:*.jpeg=01;35:*.mjpg=01;35:*.mjpeg=01;35:*.gif=01;35:*.bmp=01;35:*.pbm=01;35:*.pgm=01;35:*.ppm=01;35:*.tga=01;35:*.xbm=01;35:*.xpm=01;35:*.tif=01;35:*.tiff=01;35:*.png=01;35:*.svg=01;35:*.svgz=01;35:*.mng=01;35:*.pcx=01;35:*.mov=01;35:*.mpg=01;35:*.mpeg=01;35:*.m2v=01;35:*.mkv=01;35:*.webm=01;35:*.webp=01;35:*.ogm=01;35:*.mp4=01;35:*.m4v=01;35:*.mp4v=01;35:*.vob=01;35:*.qt=01;35:*.nuv=01;35:*.wmv=01;35:*.asf=01;35:*.rm=01;35:*.rmvb=01;35:*.flc=01;35:*.avi=01;35:*.fli=01;35:*.flv=01;35:*.gl=01;35:*.dl=01;35:*.xcf=01;35:*.xwd=01;35:*.yuv=01;35:*.cgm=01;35:*.emf=01;35:*.ogv=01;35:*.ogx=01;35:*.aac=00;36:*.au=00;36:*.flac=00;36:*.m4a=00;36:*.mid=00;36:*.midi=00;36:*.mka=00;36:*.mp3=00;36:*.mpc=00;36:*.ogg=00;36:*.ra=00;36:*.wav=00;36:*.oga=00;36:*.opus=00;36:*.spx=00;36:*.xspf=00;36:&#x27;, &#x27;XDG_CURRENT_DESKTOP&#x27;: &#x27;Unity&#x27;, &#x27;CONDA_PROMPT_MODIFIER&#x27;: &#x27;(training) &#x27;, &#x27;GIT_ASKPASS&#x27;: &#x27;/usr/share/code/resources/app/extensions/git/dist/askpass.sh&#x27;, &#x27;INVOCATION_ID&#x27;: &#x27;3573a86428f24f94957b4bbb7f7351ea&#x27;, &#x27;MANAGERPID&#x27;: &#x27;3684&#x27;, &#x27;CHROME_DESKTOP&#x27;: &#x27;code-url-handler.desktop&#x27;, &#x27;GJS_DEBUG_OUTPUT&#x27;: &#x27;stderr&#x27;, &#x27;NVM_DIR&#x27;: &#x27;/home/victor/.nvm&#x27;, &#x27;VSCODE_GIT_ASKPASS_EXTRA_ARGS&#x27;: &#x27;&#x27;, &#x27;LESSCLOSE&#x27;: &#x27;/usr/bin/lesspipe %s %s&#x27;, &#x27;XDG_SESSION_CLASS&#x27;: &#x27;user&#x27;, &#x27;TERM&#x27;: &#x27;xterm-256color&#x27;, &#x27;LC_IDENTIFICATION&#x27;: &#x27;es_ES.UTF-8&#x27;, &#x27;_CE_CONDA&#x27;: &#x27;&#x27;, &#x27;DEFAULTS_PATH&#x27;: &#x27;/usr/share/gconf/ubuntu.default.path&#x27;, &#x27;LESSOPEN&#x27;: &#x27;| /usr/bin/lesspipe %s&#x27;, &#x27;USER&#x27;: &#x27;victor&#x27;, &#x27;VSCODE_GIT_IPC_HANDLE&#x27;: &#x27;/run/user/1000/vscode-git-f3531e9239.sock&#x27;, &#x27;CONDA_SHLVL&#x27;: &#x27;2&#x27;, &#x27;DISPLAY&#x27;: &#x27;:1&#x27;, &#x27;SHLVL&#x27;: &#x27;1&#x27;, &#x27;NVM_CD_FLAGS&#x27;: &#x27;&#x27;, &#x27;LC_TELEPHONE&#x27;: &#x27;es_ES.UTF-8&#x27;, &#x27;QT_IM_MODULE&#x27;: &#x27;ibus&#x27;, &#x27;LC_MEASUREMENT&#x27;: &#x27;es_ES.UTF-8&#x27;, &#x27;PAPERSIZE&#x27;: &#x27;a4&#x27;, &#x27;CONDA_PYTHON_EXE&#x27;: &#x27;/home/victor/anaconda3/bin/python&#x27;, &#x27;XDG_RUNTIME_DIR&#x27;: &#x27;/run/user/1000&#x27;, &#x27;PS1&#x27;: &#x27;\\\\[\\x1b]633;A\\x07\\\\](training) (base) \\\\[\\\\e]0;\\\\u@\\\\h: \\\\w\\\\a\\\\]${debian_chroot:+($debian_chroot)}\\\\[\\\\033[01;32m\\\\]\\\\u@\\\\h\\\\[\\\\033[00m\\\\]:\\\\[\\\\033[01;34m\\\\]\\\\w\\\\[\\\\033[00m\\\\]\\\\$ \\\\[\\x1b]633;B\\x07\\\\]&#x27;, &#x27;CONDA_DEFAULT_ENV&#x27;: &#x27;training&#x27;, &#x27;LC_TIME&#x27;: &#x27;es_ES.UTF-8&#x27;, &#x27;VSCODE_GIT_ASKPASS_MAIN&#x27;: &#x27;/usr/share/code/resources/app/extensions/git/dist/askpass-main.js&#x27;, &#x27;JOURNAL_STREAM&#x27;: &#x27;8:49172&#x27;, &#x27;XDG_DATA_DIRS&#x27;: &#x27;/usr/share/ubuntu:/usr/share/gnome:/usr/local/share/:/usr/share/:/var/lib/snapd/desktop&#x27;, &#x27;GDK_BACKEND&#x27;: &#x27;x11&#x27;, &#x27;PATH&#x27;: &#x27;/home/victor/.local/bin:/opt/cmake/bin:/home/victor/anaconda3/envs/training/bin:/home/victor/anaconda3/condabin:/home/victor/.nvm/versions/node/v18.19.0/bin:/home/victor/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/snap/bin:/opt/cmake/bin:/home/victor/.nvm/versions/node/v18.19.0/bin:/home/victor/.local/bin:/opt/cmake/bin:/home/victor/anaconda3/bin:/home/victor/anaconda3/condabin:/home/victor/.nvm/versions/node/v18.19.0/bin:/home/victor/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/snap/bin:/home/victor/.local/bin:/opt/cmake/bin:/home/victor/anaconda3/bin:/home/victor/anaconda3/condabin:/home/victor/.nvm/versions/node/v18.19.0/bin:/home/victor/.local/bin:/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/usr/games:/usr/local/games:/snap/bin:/snap/bin&#x27;, &#x27;GDMSESSION&#x27;: &#x27;ubuntu&#x27;, &#x27;ORIGINAL_XDG_CURRENT_DESKTOP&#x27;: &#x27;ubuntu:GNOME&#x27;, &#x27;DBUS_SESSION_BUS_ADDRESS&#x27;: &#x27;unix:path=/run/user/1000/bus&#x27;, &#x27;NVM_BIN&#x27;: &#x27;/home/victor/.nvm/versions/node/v18.19.0/bin&#x27;, &#x27;CONDA_PREFIX_1&#x27;: &#x27;/home/victor/anaconda3&#x27;, &#x27;CONDA_PREFIX_2&#x27;: &#x27;/home/victor/anaconda3/envs/training&#x27;, &#x27;GIO_LAUNCHED_DESKTOP_FILE_PID&#x27;: &#x27;8409&#x27;, &#x27;GIO_LAUNCHED_DESKTOP_FILE&#x27;: &#x27;/usr/share/applications/code.desktop&#x27;, &#x27;LC_NUMERIC&#x27;: &#x27;es_ES.UTF-8&#x27;, &#x27;TERM_PROGRAM&#x27;: &#x27;vscode&#x27;, &#x27;_&#x27;: &#x27;/home/victor/anaconda3/envs/training/bin/pdoc&#x27;, &#x27;KMP_DUPLICATE_LIB_OK&#x27;: &#x27;True&#x27;, &#x27;KMP_INIT_AT_FORK&#x27;: &#x27;FALSE&#x27;, &#x27;TOKENIZERS_PARALLELISM&#x27;: &#x27;false&#x27;, &#x27;MLFLOW_TRACKING_URI&#x27;: &#x27;databricks&#x27;, &#x27;MLFLOW_EXPERIMENT_NAME&#x27;: &#x27;/fever-code-challenge&#x27;, &#x27;MLFLOW_RUN_ID&#x27;: &#x27;b4c9bfbb6abf475f8ad2c9a3688312a0&#x27;}"}, {"fullname": "src.training.training_pipeline", "modulename": "src.training.training_pipeline", "kind": "module", "doc": "<p></p>\n"}, {"fullname": "src.training.training_pipeline.logger", "modulename": "src.training.training_pipeline", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger src.training.training_pipeline (INFO)&gt;"}, {"fullname": "src.training.training_pipeline.create_datasets", "modulename": "src.training.training_pipeline", "qualname": "create_datasets", "kind": "function", "doc": "<p>Divides the data into train, validation, and test and creates PyTorch Datasets.</p>\n\n<p>Args:\n    df (DataFrame): DataFrame containing the preprocessed data.\n    label_encoder (LabelEncoder): Encoder for the labels.\n    tokenizer (AutoTokenizer): BERT tokenizer.\n    encoded (bool): Whether the data is already encoded.\n    max_length (int): Maximum length of the input sequence for BERT Tokenizer. Defaults to 512.\n    seed (int): Random seed for reproducibility. Defaults to 42.</p>\n\n<p>Returns:\n    tuple[ProductIterableDataset, ProductIterableDataset, ProductIterableDataset]: Train, validation, and test datasets.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">df</span><span class=\"p\">:</span> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>,</span><span class=\"param\">\t<span class=\"n\">label_encoder</span><span class=\"p\">:</span> <span class=\"n\">sklearn</span><span class=\"o\">.</span><span class=\"n\">preprocessing</span><span class=\"o\">.</span><span class=\"n\">_label</span><span class=\"o\">.</span><span class=\"n\">LabelEncoder</span>,</span><span class=\"param\">\t<span class=\"n\">tokenizer</span><span class=\"p\">:</span> <span class=\"n\">transformers</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">auto</span><span class=\"o\">.</span><span class=\"n\">tokenization_auto</span><span class=\"o\">.</span><span class=\"n\">AutoTokenizer</span>,</span><span class=\"param\">\t<span class=\"n\">encoded</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">max_length</span><span class=\"o\">=</span><span class=\"mi\">512</span>,</span><span class=\"param\">\t<span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"mi\">42</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"n\">src</span><span class=\"o\">.</span><span class=\"n\">training</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">product_dataset</span><span class=\"o\">.</span><span class=\"n\">ProductIterableDataset</span><span class=\"p\">,</span> <span class=\"n\">src</span><span class=\"o\">.</span><span class=\"n\">training</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">product_dataset</span><span class=\"o\">.</span><span class=\"n\">ProductIterableDataset</span><span class=\"p\">,</span> <span class=\"n\">src</span><span class=\"o\">.</span><span class=\"n\">training</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">product_dataset</span><span class=\"o\">.</span><span class=\"n\">ProductIterableDataset</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.training.training_pipeline.create_in_memory_datasets", "modulename": "src.training.training_pipeline", "qualname": "create_in_memory_datasets", "kind": "function", "doc": "<p>Divides the data into train, validation, and test and creates PyTorch Datasets.</p>\n\n<p>Args:\n    df (pd.DataFrame): DataFrame containing the preprocessed data.\n    label_encoder (LabelEncoder): Encoder for the labels.\n    tokenizer (AutoTokenizer): BERT tokenizer.\n    encoded (bool): Whether the data is already encoded.\n    max_length (int): Maximum length of the input sequence for BERT Tokenizer. Defaults to 512.\n    seed (int): Random seed for reproducibility. Defaults to 42.</p>\n\n<p>Returns:\n    tuple[ProductDataset, ProductDataset, ProductDataset]: Train, validation, and test datasets.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">df</span><span class=\"p\">:</span> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>,</span><span class=\"param\">\t<span class=\"n\">label_encoder</span><span class=\"p\">:</span> <span class=\"n\">sklearn</span><span class=\"o\">.</span><span class=\"n\">preprocessing</span><span class=\"o\">.</span><span class=\"n\">_label</span><span class=\"o\">.</span><span class=\"n\">LabelEncoder</span>,</span><span class=\"param\">\t<span class=\"n\">tokenizer</span><span class=\"p\">:</span> <span class=\"n\">transformers</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">auto</span><span class=\"o\">.</span><span class=\"n\">tokenization_auto</span><span class=\"o\">.</span><span class=\"n\">AutoTokenizer</span>,</span><span class=\"param\">\t<span class=\"n\">encoded</span><span class=\"p\">:</span> <span class=\"nb\">bool</span>,</span><span class=\"param\">\t<span class=\"n\">max_length</span><span class=\"o\">=</span><span class=\"mi\">512</span>,</span><span class=\"param\">\t<span class=\"n\">seed</span><span class=\"o\">=</span><span class=\"mi\">42</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"n\">src</span><span class=\"o\">.</span><span class=\"n\">training</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">product_dataset</span><span class=\"o\">.</span><span class=\"n\">ProductDataset</span><span class=\"p\">,</span> <span class=\"n\">src</span><span class=\"o\">.</span><span class=\"n\">training</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">product_dataset</span><span class=\"o\">.</span><span class=\"n\">ProductDataset</span><span class=\"p\">,</span> <span class=\"n\">src</span><span class=\"o\">.</span><span class=\"n\">training</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">product_dataset</span><span class=\"o\">.</span><span class=\"n\">ProductDataset</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.training.training_pipeline.create_loaders", "modulename": "src.training.training_pipeline", "qualname": "create_loaders", "kind": "function", "doc": "<p>Creates DataLoaders for training, validation, and testing.</p>\n\n<p>Args:\n    train_dataset (ProductIterableDataset): Training dataset.\n    val_dataset (ProductIterableDataset): Validation dataset.\n    test_dataset (ProductIterableDataset): Test dataset.\n    batch_size (int): Batch size for training and validation.\n    test_batch_size (int): Batch size for testing.</p>\n\n<p>Returns:\n    tuple[DataLoader, DataLoader, DataLoader]: Train, validation, and test DataLoaders.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">train_dataset</span><span class=\"p\">:</span> <span class=\"n\">src</span><span class=\"o\">.</span><span class=\"n\">training</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">product_dataset</span><span class=\"o\">.</span><span class=\"n\">ProductIterableDataset</span>,</span><span class=\"param\">\t<span class=\"n\">val_dataset</span><span class=\"p\">:</span> <span class=\"n\">src</span><span class=\"o\">.</span><span class=\"n\">training</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">product_dataset</span><span class=\"o\">.</span><span class=\"n\">ProductIterableDataset</span>,</span><span class=\"param\">\t<span class=\"n\">test_dataset</span><span class=\"p\">:</span> <span class=\"n\">src</span><span class=\"o\">.</span><span class=\"n\">training</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">product_dataset</span><span class=\"o\">.</span><span class=\"n\">ProductIterableDataset</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">test_batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.training.training_pipeline.create_in_memory_loaders", "modulename": "src.training.training_pipeline", "qualname": "create_in_memory_loaders", "kind": "function", "doc": "<p>Creates DataLoaders for training, validation, and testing.</p>\n\n<p>Args:\n    train_dataset (ProductDataset): Training dataset.\n    val_dataset (ProductDataset): Validation dataset.\n    test_dataset (ProductDataset): Test dataset.\n    batch_size (int): Batch size for training and validation.\n    test_batch_size (int): Batch size for testing.</p>\n\n<p>Returns:\n    tuple[DataLoader, DataLoader, DataLoader]: Train, validation, and test DataLoaders.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">train_dataset</span><span class=\"p\">:</span> <span class=\"n\">src</span><span class=\"o\">.</span><span class=\"n\">training</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">product_dataset</span><span class=\"o\">.</span><span class=\"n\">ProductDataset</span>,</span><span class=\"param\">\t<span class=\"n\">val_dataset</span><span class=\"p\">:</span> <span class=\"n\">src</span><span class=\"o\">.</span><span class=\"n\">training</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">product_dataset</span><span class=\"o\">.</span><span class=\"n\">ProductDataset</span>,</span><span class=\"param\">\t<span class=\"n\">test_dataset</span><span class=\"p\">:</span> <span class=\"n\">src</span><span class=\"o\">.</span><span class=\"n\">training</span><span class=\"o\">.</span><span class=\"n\">datasets</span><span class=\"o\">.</span><span class=\"n\">product_dataset</span><span class=\"o\">.</span><span class=\"n\">ProductDataset</span>,</span><span class=\"param\">\t<span class=\"n\">batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">test_batch_size</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">tuple</span><span class=\"p\">[</span><span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span><span class=\"p\">,</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span><span class=\"p\">]</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.training.training_pipeline.plot_confusion_matrix", "modulename": "src.training.training_pipeline", "qualname": "plot_confusion_matrix", "kind": "function", "doc": "<p>Plots and logs the confusion matrix.</p>\n\n<p>Args:\n    cm (np.ndarray): Confusion matrix.\n    labels (list[str]): List of class labels.\n    log (bool): Whether to log the plot to MLflow. Defaults to True.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">cm</span><span class=\"p\">:</span> <span class=\"n\">numpy</span><span class=\"o\">.</span><span class=\"n\">ndarray</span>, </span><span class=\"param\"><span class=\"n\">labels</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>, </span><span class=\"param\"><span class=\"n\">log</span><span class=\"p\">:</span> <span class=\"nb\">bool</span> <span class=\"o\">=</span> <span class=\"kc\">True</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.training_pipeline.train", "modulename": "src.training.training_pipeline", "qualname": "train", "kind": "function", "doc": "<p>Trains the model for one epoch.</p>\n\n<p>Args:\n    loader (DataLoader): PyTorch DataLoader for training data.\n    model (AutoModelForSequenceClassification): BERT model for text classification.\n    optimizer (AdamW): Optimizer for training.\n    scheduler (LambdaLR): Learning rate scheduler.\n    device (str): Device to use for training.\n    epoch (int): Current epoch number.\n    num_epochs (int): Total number of epochs.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">loader</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span>,</span><span class=\"param\">\t<span class=\"n\">model</span><span class=\"p\">:</span> <span class=\"n\">transformers</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">auto</span><span class=\"o\">.</span><span class=\"n\">modeling_auto</span><span class=\"o\">.</span><span class=\"n\">AutoModelForSequenceClassification</span>,</span><span class=\"param\">\t<span class=\"n\">optimizer</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">adamw</span><span class=\"o\">.</span><span class=\"n\">AdamW</span>,</span><span class=\"param\">\t<span class=\"n\">scheduler</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">optim</span><span class=\"o\">.</span><span class=\"n\">lr_scheduler</span><span class=\"o\">.</span><span class=\"n\">LambdaLR</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">epoch</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_epochs</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.training_pipeline.evaluate", "modulename": "src.training.training_pipeline", "qualname": "evaluate", "kind": "function", "doc": "<p>Evaluates the model on the validation set after each training epoch.</p>\n\n<p>Args:\n    loader (DataLoader): PyTorch DataLoader for validation data.\n    model (AutoModelForSequenceClassification): BERT model for text classification.\n    device (str): Device to use for evaluation.\n    epoch (int): Current epoch number.\n    num_epochs (int): Total number of epochs.</p>\n\n<p>Returns:\n    float: Validation loss.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">loader</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span>,</span><span class=\"param\">\t<span class=\"n\">model</span><span class=\"p\">:</span> <span class=\"n\">transformers</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">auto</span><span class=\"o\">.</span><span class=\"n\">modeling_auto</span><span class=\"o\">.</span><span class=\"n\">AutoModelForSequenceClassification</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"nb\">str</span>,</span><span class=\"param\">\t<span class=\"n\">epoch</span><span class=\"p\">:</span> <span class=\"nb\">int</span>,</span><span class=\"param\">\t<span class=\"n\">num_epochs</span><span class=\"p\">:</span> <span class=\"nb\">int</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.training_pipeline.test", "modulename": "src.training.training_pipeline", "qualname": "test", "kind": "function", "doc": "<p>Tests the model on the test set.</p>\n\n<p>Args:\n    loader (DataLoader): PyTorch DataLoader for test data.\n    decoded_categories (list[str]): List of decoded category labels.\n    model (AutoModelForSequenceClassification): BERT model for text classification.\n    device (str): Device to use for testing.</p>\n\n<p>Returns:\n    dict: Dictionary containing the test metrics.</p>\n", "signature": "<span class=\"signature pdoc-code multiline\">(<span class=\"param\">\t<span class=\"n\">loader</span><span class=\"p\">:</span> <span class=\"n\">torch</span><span class=\"o\">.</span><span class=\"n\">utils</span><span class=\"o\">.</span><span class=\"n\">data</span><span class=\"o\">.</span><span class=\"n\">dataloader</span><span class=\"o\">.</span><span class=\"n\">DataLoader</span>,</span><span class=\"param\">\t<span class=\"n\">decoded_categories</span><span class=\"p\">:</span> <span class=\"nb\">list</span><span class=\"p\">[</span><span class=\"nb\">str</span><span class=\"p\">]</span>,</span><span class=\"param\">\t<span class=\"n\">model</span><span class=\"p\">:</span> <span class=\"n\">transformers</span><span class=\"o\">.</span><span class=\"n\">models</span><span class=\"o\">.</span><span class=\"n\">auto</span><span class=\"o\">.</span><span class=\"n\">modeling_auto</span><span class=\"o\">.</span><span class=\"n\">AutoModelForSequenceClassification</span>,</span><span class=\"param\">\t<span class=\"n\">device</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.training_pipeline.run", "modulename": "src.training.training_pipeline", "qualname": "run", "kind": "function", "doc": "<p>Function to run the training pipeline.</p>\n\n<p>Args:\n    config (str): Path to the configuration file. Defaults to 'src/training/default_config.yml'.\n        input_data_path (str): Path to the input JSONL.gz file.\n        input_data_encoded (bool): Whether the data is already encoded. Defaults to False.\n        bert_model_name (str): Name of the BERT model to use for tokenization. Defaults to 'bert-base-uncased'.\n        data_load ('memory' | 'distributed'): Method to load the data. Defaults to 'distributed'.\n        trainable_layers (int | None): Number of layers to keep trainable. None for all layers. Defaults to None.\n        num_epochs (int): Number of epochs to train the model. Defaults to 3.\n        batch_size (int): Batch size for training and validation. Defaults to 8.\n        test_batch_size (int): Batch size for testing. Defaults to 32.\n        learning_rate (float): Learning rate for the optimizer. Defaults to 1e-5.\n        optimizer (str): Optimizer to use for training. Defaults to 'AdamW'.\n        seed (int): Random seed for reproducibility. Defaults to 42.\n        device (str): Device to use for training. Defaults to 'cuda'.\n        data_fraction (float): Fraction of the data to sample for training. Defaults to 1.0.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">config</span><span class=\"o\">=</span><span class=\"s1\">&#39;src/training/configs/default_config.yml&#39;</span>, </span><span class=\"param\"><span class=\"o\">**</span><span class=\"n\">overrides</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.utils", "modulename": "src.training.utils", "kind": "module", "doc": "<p>Module for utility functions.</p>\n"}, {"fullname": "src.training.utils.get_logger", "modulename": "src.training.utils", "qualname": "get_logger", "kind": "function", "doc": "<p>Template for getting a logger.</p>\n\n<p>Args:\n    name: Name of the logger.</p>\n\n<p>Returns: Logger.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">name</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">logging</span><span class=\"o\">.</span><span class=\"n\">Logger</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.training.utils.logger", "modulename": "src.training.utils", "qualname": "logger", "kind": "variable", "doc": "<p></p>\n", "default_value": "&lt;Logger src.training.utils (INFO)&gt;"}, {"fullname": "src.training.utils.read_jsonl_to_pandas", "modulename": "src.training.utils", "qualname": "read_jsonl_to_pandas", "kind": "function", "doc": "<p>Reads a Parquet file into a Pandas DataFrame.</p>\n\n<p>Args:\n    path (str): The path to the Parquet file.</p>\n\n<p>Returns:\n    pd.DataFrame: A Pandas DataFrame containing the data from the Parquet file.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.training.utils.read_parquet_to_pandas", "modulename": "src.training.utils", "qualname": "read_parquet_to_pandas", "kind": "function", "doc": "<p>Reads a Parquet file into a Pandas DataFrame.</p>\n\n<p>Args:\n    path (str): The path to the Parquet file.\n    use_pyspark (bool): Whether to use PySpark to read the Parquet file. Defaults to False.</p>\n\n<p>Returns:\n    pd.DataFrame: A Pandas DataFrame containing the data from the Parquet file.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span><span class=\"p\">:</span> <span class=\"nb\">str</span>, </span><span class=\"param\"><span class=\"n\">use_pyspark</span><span class=\"o\">=</span><span class=\"kc\">False</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pandas</span><span class=\"o\">.</span><span class=\"n\">core</span><span class=\"o\">.</span><span class=\"n\">frame</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.training.utils.read_jsonl_to_pyspark", "modulename": "src.training.utils", "qualname": "read_jsonl_to_pyspark", "kind": "function", "doc": "<p>Returns a Spark DataFrame from the JSON objects in the gzip file.</p>\n\n<p>Args:\n    path (str): The path to the gzip file.</p>\n\n<p>Returns:\n    DataFrame: A Spark DataFrame containing the JSON objects.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.training.utils.read_parquet_to_pyspark", "modulename": "src.training.utils", "qualname": "read_parquet_to_pyspark", "kind": "function", "doc": "<p>Reads a Parquet file into a PySpark DataFrame.</p>\n\n<p>Args:\n    path (str): The path to the Parquet file.</p>\n\n<p>Returns:\n    DataFrame: A PySpark DataFrame containing the data from the Parquet file.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"n\">pyspark</span><span class=\"o\">.</span><span class=\"n\">sql</span><span class=\"o\">.</span><span class=\"n\">dataframe</span><span class=\"o\">.</span><span class=\"n\">DataFrame</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.training.utils.set_seed", "modulename": "src.training.utils", "qualname": "set_seed", "kind": "function", "doc": "<p>Set the random seed for reproducibility.</p>\n\n<p>Args:\n    seed (int): Random seed.\n    device (str): Device to set seed for. Defaults to 'cuda'.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">seed</span>, </span><span class=\"param\"><span class=\"n\">device</span><span class=\"o\">=</span><span class=\"s1\">&#39;cuda&#39;</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}, {"fullname": "src.training.utils.load_config", "modulename": "src.training.utils", "qualname": "load_config", "kind": "function", "doc": "<p>Load configuration file from yml file on the specified path.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">config_path</span><span class=\"p\">:</span> <span class=\"nb\">str</span></span><span class=\"return-annotation\">) -> <span class=\"nb\">dict</span>:</span></span>", "funcdef": "def"}, {"fullname": "src.training.utils.freeze_layers", "modulename": "src.training.utils", "qualname": "freeze_layers", "kind": "function", "doc": "<p>Freezes all layers except the last layers_count layers.</p>\n\n<p>Args:\n    model: PyTorch model.\n    layers_count: Number of layers to keep trainable.</p>\n\n<p>Returns:\n    int: The number of trainable parameters.\n    list: List of layers that are trainable.</p>\n", "signature": "<span class=\"signature pdoc-code condensed\">(<span class=\"param\"><span class=\"n\">model</span>, </span><span class=\"param\"><span class=\"n\">layers_count</span></span><span class=\"return-annotation\">):</span></span>", "funcdef": "def"}];

    // mirrored in build-search-index.js (part 1)
    // Also split on html tags. this is a cheap heuristic, but good enough.
    elasticlunr.tokenizer.setSeperator(/[\s\-.;&_'"=,()]+|<[^>]*>/);

    let searchIndex;
    if (docs._isPrebuiltIndex) {
        console.info("using precompiled search index");
        searchIndex = elasticlunr.Index.load(docs);
    } else {
        console.time("building search index");
        // mirrored in build-search-index.js (part 2)
        searchIndex = elasticlunr(function () {
            this.pipeline.remove(elasticlunr.stemmer);
            this.pipeline.remove(elasticlunr.stopWordFilter);
            this.addField("qualname");
            this.addField("fullname");
            this.addField("annotation");
            this.addField("default_value");
            this.addField("signature");
            this.addField("bases");
            this.addField("doc");
            this.setRef("fullname");
        });
        for (let doc of docs) {
            searchIndex.addDoc(doc);
        }
        console.timeEnd("building search index");
    }

    return (term) => searchIndex.search(term, {
        fields: {
            qualname: {boost: 4},
            fullname: {boost: 2},
            annotation: {boost: 2},
            default_value: {boost: 2},
            signature: {boost: 2},
            bases: {boost: 2},
            doc: {boost: 1},
        },
        expand: true
    });
})();